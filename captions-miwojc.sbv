0:00:00.219,0:00:05.399
Cześć wszystkim i witamy na pierwszej lekcji głębokiego uczenia dla programistów

0:00:06.129,0:00:08.129
To jest czwarty

0:00:08.170,0:00:10.439
rok, w którym prowadzimy ten kurs

0:00:11.230,0:00:12.820
Ale jest on

0:00:12.820,0:00:14.820
bardzo różny i bardzo

0:00:14.920,0:00:16.150
specjalny

0:00:16.150,0:00:19.559
z wielu powodów. Pierwszym powodem jest to, że

0:00:19.840,0:00:26.219
nadajemy go na żywo w pierwszym dniu całkowitego zamknięcia lub niepełnego zamknięcia

0:00:26.220,0:00:28.349
Ale prawie całkowitego zamknięcie w San Francisco

0:00:29.050,0:00:34.050
Będziemy go nagrywać w ciągu najbliższych dwóch miesięcy w trakcie tej globalnej epidemii

0:00:34.050,0:00:41.399
Więc jeżeli czasami ten kurs wydaje się trochę szalony, przepraszam, ​​ale właśnie dlatego tak się dzieje.

0:00:42.940,0:00:47.160
Innym powodem, dla którego ten kurs jest wyjątkowy, jest to, że

0:00:49.090,0:00:52.889
Staramy się, aby była to nasza ostateczna wersja, prawda.

0:00:53.949,0:00:55.840
Odkąd prowadzimy ten kurs już od jakiegoś czasu

0:00:55.840,0:01:00.329
W końcu doszliśmy do punktu, w którym prawie czujemy, że wiemy, o czym mówimy

0:01:00.940,0:01:05.129
Do tego stopnia, że ​​Sylvain i ja napisaliśmy książkę

0:01:05.650,0:01:08.999
I napisaliśmy oprogramowanie od zera

0:01:09.369,0:01:14.849
Nazywające się biblioteką fastai w wersji 2. Napisaliśmy recenzowany artykuł o tej bibliotece

0:01:16.450,0:01:22.830
Więc jest to coś w rodzaju wersji kursu

0:01:24.070,0:01:26.070
który będzie służył nam przez długi czas

0:01:27.250,0:01:31.650
Program kursu oparty jest bardzo ściśle na tej książce, prawda.

0:01:31.810,0:01:36.060
Więc jeśli chcesz ją czytać razem z kursem

0:01:37.030,0:01:38.320
Proszę, kup ją

0:01:38.320,0:01:43.349
i mówię, proszę, kup ją, bo tak naprawdę cała książka jest dostępna za darmo w

0:01:43.869,0:01:47.578
formie notatników Jupiter Notebooks, a to dzięki

0:01:48.159,0:01:49.479
olbrzymiej

0:01:49.479,0:01:53.188
hojności wydawnictwa O'Reilly, które nam na to pozwoliło

0:01:54.159,0:01:55.810
więc

0:01:55.810,0:01:57.159
dobrze

0:01:57.159,0:02:01.618
Będziecie mogli zobaczyć na stronie kursu, jak dostać dostęp do tego wszystkiego

0:02:02.920,0:02:04.920
ale

0:02:05.380,0:02:09.810
Oto repozytorium książki "fastbook", gdzie możecie przeczytać tą całą cholerną rzecz

0:02:12.040,0:02:14.730
W tej chwili, jak widzicie, jest to wersja wstępna, ale do czasu

0:02:15.489,0:02:17.489
jak to zobaczycie, już nie będzie

0:02:18.040,0:02:21.030
Więc mamy tutaj wielką prośbę

0:02:21.879,0:02:23.110
um

0:02:23.110,0:02:25.110
Umowa jest taka

0:02:25.300,0:02:29.039
Możecie czytać to ją za darmo jako notatniki Jupyter Notebooks, ale

0:02:30.010,0:02:35.910
to nie jest tak wygodne, jak czytanie jej na Kindle lub wiesz w książce papierowej lub czymkolwiek

0:02:35.920,0:02:41.250
Więc proszę, nie przekształcajcie jej w plik PDF, prawda. Proszę, nie zmieniajcie jej w

0:02:42.240,0:02:44.240
formę przeznaczona bardziej do czytania

0:02:44.940,0:02:50.700
Ponieważ w pewnym sensie chodzi o to, że mamy nadzieję, że wiesz, że kupisz ją dobrze, nie nie

0:02:51.580,0:02:53.920
wykorzystujcie hojności O'Reilly

0:02:54.549,0:02:56.019
przez

0:02:56.019,0:02:58.019
tworzenie rzecz, którą

0:02:58.030,0:03:05.099
Wiesz, nie dają ci za darmo. I to jest wyraźnie licencja, na podstawie której my również ją udostępniamy

0:03:05.099,0:03:07.099
Więc jest coś, wiesz

0:03:07.150,0:03:09.450
Jest to głównie prośba o bycie porządnym człowiekiem

0:03:10.060,0:03:15.119
Jeśli widzicie, że ktoś inny nie jest przyzwoitym człowiekiem i kradnie książkową wersję książki

0:03:15.120,0:03:19.679
Powiedzcie im, proszę, nie róbcie tego. To nie jest miłe i nie bądźcie takimi osobami

0:03:21.010,0:03:26.970
Tak czy inaczej możecie czytać wraz z programem zawartym w książce

0:03:28.480,0:03:35.190
Istnieje kilka różnych wersji tych notatników, prawda, jest tam

0:03:38.049,0:03:41.578
Tam jest pełny notatnik

0:03:43.030,0:03:48.509
Który ma całą prozę, zdjęcia, wszystko. My napisaliśmy

0:03:50.200,0:03:57.569
system, który zamienia notatniki w drukowaną książkę, a czasem wygląda to trochę dziwnie, na przykład

0:03:58.510,0:04:03.480
tutaj jest dziwnie wyglądająca tabela i jeśli zajrzycie do prawdziwej książki

0:04:05.019,0:04:11.459
Wtedy wygląda jak właściwa tabla. Więc czasami zobaczysz trochę dziwnych kawałków

0:04:11.459,0:04:17.939
Okej, to nie pomyłki. Są to fragmenty, w których dodajemy informacje, które pomogą nam zmienić tą książkę we właściwą fajną książkę

0:04:17.940,0:04:19.940
Więc po prostu je zignoruj

0:04:25.570,0:04:28.749
jedną ważna część nas jest

0:04:29.660,0:04:35.860
Sylvain. Sylvain jest moim współautorem książki i biblioteki fastai w wersji 2.

0:04:35.860,0:04:38.139
Więc jest on moim partnerem w zbrodni

0:04:39.190,0:04:41.090
drugim kluczowym

0:04:41.090,0:04:43.090
my tutaj

0:04:43.640,0:04:49.990
Jest Rachel Thomas, a więc może Rachel, możesz przyjść i przywitać się. Jest ona współzałożycielką fast.ai.

0:04:53.510,0:04:55.749
Witam, jestem współzałożycielem fast.ai.

0:04:56.780,0:05:04.630
Niżej. Przepraszam, jestem wyższa niż Jeremy, i jestem dyrektorem założycielem Centre for applied data ethics na Uniwersytecie w San Francisco

0:05:05.360,0:05:10.599
Jestem naprawdę podekscytowana uczestnictwem w tym kursie i będę głosem, który usłyszycie który czyta pytania zadawane na forach

0:05:15.050,0:05:20.979
Rachel i Sylvain są również ludźmi z tej grupy, którzy faktycznie rozumieją matematykę. Ja jestem zwykłym absolwentem filozofii

0:05:21.830,0:05:26.319
Rachel ma doktorat, Silvain napisał 10 książek o matematyce. Więc

0:05:26.900,0:05:29.799
Jeśli pojawią się pytania matematyczne, to mogę

0:05:30.320,0:05:32.320
Przekazać je do nich

0:05:32.330,0:05:37.059
Ale bardzo miło jest mieć możliwość pracy z ludźmi, którzy rozumieją ten temat tak dobrze

0:05:38.360,0:05:40.419
Tak. Tak, Rachel. Chciałeś

0:05:41.990,0:05:48.069
Jasne, dziękuję. Jak Rachel wspomniała, drugim obszarem, w którym ona jest

0:05:49.400,0:05:56.199
Wiesz, ma prawdziwą wiedzę światowej klasy to etyka danych. Jest dyrektorem założycielem Center for Applied Data Ethics

0:06:00.230,0:06:02.230
Na Uniwersytecie w San Francisco. Dziękuję Ci

0:06:02.720,0:06:09.279
Przez cały kurs będziemy rozmawiać o etyce danych, ponieważ uważamy to za bardzo ważne

0:06:09.890,0:06:15.490
Tak więc te części, chociaż ogólnie je przedstawię. Będą one w całości oparte na

0:06:16.400,0:06:17.570
pracy Rachel.

0:06:17.570,0:06:20.110
Ponieważ ona wie o czym mówi

0:06:21.470,0:06:24.460
Chociaż dzięki niej. Ja też trochę  wiem o tym, o czym mówię.

0:06:25.760,0:06:27.760
Racja, więc to tyle

0:06:31.040,0:06:37.420
Więc, czy powinniście tu być? Czy jest jakiś punkt, który próbujesz zrozumieć?

0:06:40.549,0:06:42.549
Zrozumieć w głębokim uczeniu

0:06:44.719,0:06:52.719
Okej, więc co, wiesz co, czy powinniście tu być? Czy jest jakiś punkt, którego próbujesz nauczyć się w głębokim uczeniu. Czy jesteś

0:06:53.539,0:07:00.998
Zbyt głupi, albo nie masz wystarczającej ilości ogromnych zasobów, czy cokolwiek innego, ponieważ tak mówi nam wiele osób

0:07:00.999,0:07:06.368
Mówią, że potrzebujesz zespołów doktorów i ogromnych centrów danych pełnych GPU. Inaczej

0:07:06.889,0:07:08.889
To nie ma sensu

0:07:09.199,0:07:15.338
Nie martw się. To wcale nie jest prawda. To nie może być dalsze od prawdy. W rzeczywistości ogroma większść

0:07:17.629,0:07:19.629
Wieke światowej klasy

0:07:19.669,0:07:26.378
badań i światowej klasy projektów przemysłówych wywodzi się od absolwentów fastai i

0:07:27.709,0:07:29.709
fastai

0:07:30.139,0:07:34.179
Projektów opartych na bibliotece fastai i gdzie indziej

0:07:35.239,0:07:37.239
Które zostały utworzone na jednym GPU

0:07:37.459,0:07:38.719
za pomocą

0:07:38.719,0:07:44.469
kilkudziesięciu lub kilkuset punktów danych przez osóby, które nie mają

0:07:45.559,0:07:46.969
doświadczenia technicznego na poziomie wyższego wykształcenia

0:07:46.969,0:07:53.859
lub w moim przypadku, ja nie mam specjalistycznej wiedzy technicznej na poziomie licencjackim. Jestem po prostu filozofem z wykształcenia

0:07:54.619,0:07:56.599
więc tam jest

0:07:56.599,0:07:58.089
I zobaczymy to w trakcie kursu

0:07:58.089,0:08:03.099
Ale jest wiele, wiele empirycznych dowodów na to, że nie potrzebujesz dużo matematyki

0:08:03.099,0:08:08.259
Nie potrzebujesz dużo danych. Nie potrzebujesz wielu drogich komputerów, aby robić świetne rzeczy z głębokim uczeniem. Więc

0:08:08.989,0:08:10.989
Po prostu się z nami trzymaj. Będzie dobrze.

0:08:11.779,0:08:13.779
Aby skończyć ten kurs, potrzebujesz kodować

0:08:15.469,0:08:17.469
Najlepiej gdy wiesz, jak kodować w Pythonie

0:08:18.259,0:08:19.989
ale jeśli znasz inne języki

0:08:19.989,0:08:21.989
Możesz nauczyć się Python-a

0:08:22.069,0:08:28.208
Jeśli jedynymi językami, w których programowałeś, jest coś podobnego do MATLAB, gdzie używałeś go bardziej jak języka skryptowego

0:08:28.939,0:08:31.629
Może to być dla Ciebie trochę. Będzie to dla Ciebie trochę cięższe

0:08:32.990,0:08:37.419
Ale to dobrze, kontynuuj. Możesz uczyć się języka Python w trakcie

0:08:40.399,0:08:44.318
Czy uczenie się głębokiego uczenia ma sens, czy jest ono w czymś dobre?

0:08:44.930,0:08:48.729
Jeśli masz nadzieję zbudować mózg

0:08:49.699,0:08:51.559
któy jest AGI

0:08:51.559,0:08:59.229
Nie mogę obiecać, że ci w tym pomożemy, a AGI oznacza ogólną sztuczną inteligencję. Dziękuję Ci

0:09:00.130,0:09:03.520
Mogę Ci jednak powiedzieć, że we wszystkich tych obszarach.

0:09:04.130,0:09:10.900
Głębokie uczenie jest najlepszym rozwiązaniem do, co najmniej do wielu wersji wszystkich tych rzeczy

0:09:12.290,0:09:13.850
więc jest to

0:09:13.850,0:09:17.740
W tym momencie nie spekuluje się, czy jest to przydatne narzędzie

0:09:17.740,0:09:24.609
Jest to przydatne narzędzie w wielu, wielu miejscach, niezwykle przydatnych narzędzie. I w wielu tych przypadków

0:09:25.580,0:09:31.449
jest równoważne lub lepsze niż ludzka wydajność przynajmniej według pewnego szczególnego rodzaju zawężenia

0:09:31.820,0:09:35.020
definicji rzeczy, które ludzie robią w tego rodzaju obszarach.

0:09:35.780,0:09:38.379
Tak głębokie uczenie się jest niesamowite

0:09:38.390,0:09:39.260
i jeśli

0:09:39.260,0:09:44.830
chcesz zatrzymać wideo tutaj, przejrzeć i spróbować wybrać kilka rzeczy, które Twoim zdaniem

0:09:44.830,0:09:52.330
wyglądają ciekawie, i wpisz to słowo kluczowe i głębokie uczenie w Google, a znajdziesz wiele artykułów, przykładów i tego typu rzeczy

0:09:54.860,0:09:56.390
Głębokie uczenie

0:09:56.390,0:10:02.559
wywodzi się z sieci neuronowych. Jak  zobaczycie, głębokie uczenie się typem

0:10:03.770,0:10:05.770
uczenia sieci neuronowych, a dokładniej głębokiego.

0:10:06.170,0:10:12.640
Później wyjaśnie co to znaczy. Sieci neuronowe z pewnością nie są niczym nowym. Pracowano nad nimi przynajmniej do

0:10:13.250,0:10:15.250
od 1943, kiedy McCulloch i Pitts

0:10:15.560,0:10:22.239
Stworzyli model matematyczny sztucznego neuronu i bardzo się podekscytowali, doczego to może doprowadić

0:10:23.020,0:10:25.020
A potem w latach 50

0:10:25.840,0:10:27.620
Frank Rosenblatt

0:10:27.620,0:10:29.620
zbudował na podstawie tego

0:10:30.220,0:10:34.900
Zasadniczo on wprowadził subtelne zmiany w tym modelu matematycznym

0:10:35.540,0:10:41.409
I pomyślał, że dzięki tym subtelnym zmianom możemy być świadkami narodzin maszyny zdolnej do postrzegania

0:10:41.780,0:10:46.089
rozpoznawanie i identyfikowanie otoczenia bez przeszkolenia lub kontroli człowieka oraz

0:10:46.640,0:10:48.939
nadzorował on budowę tej

0:10:49.910,0:10:54.040
niezwykłej rzeczy, perceptronu mark 1 w Cornell

0:10:56.270,0:10:58.749
Myślę, że to było, to zdjęcie było z 1961 roku

0:11:00.050,0:11:06.820
Na szczęście w dzisiejszych czasach, nie musimy budować sieci neuronowych, prowadząc te cholerne druty od neurona do neurona, od sztucznego neurona do sztucznego neurona

0:11:07.070,0:11:09.309
ale możecie zobaczyć tą pomysł

0:11:09.410,0:11:14.200
Jest tu dużo połączeń. Na tym kursie często będziemy slyszeli słowo „połączenie”, bo o to w tym wszystkim chodzi

0:11:16.570,0:11:20.109
Potem mieliśmy pierwszą zimę SI, tak to nazywano, która naprawdę

0:11:20.840,0:11:25.299
w dużym stopniu zaistniała z powodu profesora MIT o nazwisku Marvin Minsky

0:11:26.000,0:11:33.520
A Papert napisał książkę o nazwie "Perceptrony" o wynalazku Rosenblatta, w której wskazali, że jedna warstwa

0:11:33.950,0:11:35.060
tych

0:11:35.060,0:11:37.060
sztucznych urządzeń neuronowych

0:11:37.280,0:11:39.080
właściwie nie mogłą się nauczyć

0:11:39.080,0:11:44.979
niektóreych kluczowe rzeczy. Było to dla niej niemożliwe do nauczenia się czegoś tak prostego, jak logiczny operator XOR

0:11:46.340,0:11:51.309
W tej samej książce wykazali, że użycie wielu warstw urządzeń faktycznie rozwiązałoby problem

0:11:51.980,0:11:55.930
ludzie zignorowali to, nie zauważyli tej części książki i tylko zauważyli

0:11:57.020,0:12:01.299
ograniczenia i ludzie w zasadzie zdecydowali, że sieci neuronowe do niczego nie doprowadzą

0:12:02.090,0:12:03.320
i

0:12:03.320,0:12:05.859
w dużej mierze one zniknęły na dziesięciolecia

0:12:06.500,0:12:07.910
aż do

0:12:07.910,0:12:10.690
W pewnym sensie do 1986 r. Wiele się również wydarzyło do tego czsu

0:12:11.390,0:12:14.169
ale w 1986 roku było coś wielkiego

0:12:14.900,0:12:21.309
MIT wydało książkę, serię dwóch tomów książki, pod tytułem "Równoległe przetwarzanie rozproszone"

0:12:23.240,0:12:26.740
W którym opisali tę rzecz, nazwaną przetwarzaniem równoległym rozproszonym

0:12:27.320,0:12:32.559
gdzie mamy kilka jednostek przetwarzających, które mają pewien stan aktywacji

0:12:32.960,0:12:37.040
i jakąś funkcję wyjściową i jakiś wzór połączeń

0:12:37.340,0:12:43.680
i jakieś zasady propagacyjne oraz jakieś zasady aktywacyjne i jakieś reguły uczenia działające w środowisku

0:12:43.960,0:12:47.640
A potem opisali, jak rzeczy któe spełniają te wymagania

0:12:48.500,0:12:52.900
Teoretycznie mogą wykonywać wiele niesamowitych prac

0:12:52.900,0:12:54.999
Był to wynik wielu

0:12:55.280,0:13:02.619
naukowców pracujących razem. Cała grupa była zaangażowani w ten projekt, który zaowocował tą bardzo ważną książką

0:13:03.080,0:13:09.909
Ciekawe jest dla mnie to, że jeśli ukończysz ten kurs, wróć i spójrz

0:13:10.280,0:13:18.219
na to zdjęcie, a zobaczysz, że robimy dokładnie te rzeczy, Wszystko czego się uczymy naprawdę jest, jak robimy

0:13:18.830,0:13:20.720
każdą z tych

0:13:20.720,0:13:25.959
ośmiu rzeczy. W porządku. I ciekawe jest, że obejmują one środowisko, ponieważ jest to coś, co bardzo często

0:13:26.720,0:13:31.509
ignorowane przez naukowców zajmujących się danych. To znaczy budujesz model, wytrenowałeś go,  on sie nauczył czegoś

0:13:31.509,0:13:37.269
W jakim kontekście działa. I my mówimy o tym również przez kilka następnych lekcji.

0:13:39.619,0:13:41.619
W latach 80

0:13:42.379,0:13:48.459
W trakcie i po tym, jak to zostało wydane, ludzie zaczęli budować w tej drugiej warstwie neuronów

0:13:48.859,0:13:52.329
unikając problemu Minsky'ego

0:13:53.179,0:13:55.179
I pokazano

0:13:55.880,0:14:02.080
I udowodniono matematycznie, że dodając jedną dodatkową warstwę neuronów było wystarczające na to by pozwolić

0:14:02.620,0:14:08.380
aby każdy moodel matematyczny był przybliżony do dowolnego poziomu dokładności za pomocą tych sieci neuronowych

0:14:09.320,0:14:13.600
I to było dokładnie odwrotne do problemu Minsky'ego

0:14:13.600,0:14:18.850
To było jak: hej, wiesz, nie ma nic, czego nie możemy zrobić, ewidentnie nie ma nic czego nie da się zrobić

0:14:18.850,0:14:22.080
I to było w czasie kiedy ja zaczęłam się angażować w sieci neuronowe

0:14:23.040,0:14:28.280
Ja zacząłem trochę później, wyydaje mi się. Ja zacząłęm angażować się w późnych latach 90.

0:14:28.840,0:14:34.880
I były one bardzo szeroko stosowane w przemyśle. Używałem ich do bardzo nudnych rzeczy, takich jak ukierunkowany marketing dla banków detalicznych

0:14:35.980,0:14:39.280
zwykle były to duże firmy z dużą ilością pieniędzy, które z nich korzystały z nich

0:14:39.640,0:14:46.660
Często sieci były zbyt duże lub zbyt wolne, aby były przydatne.

0:14:47.140,0:14:50.820
Z pewnością były przydatne do niektórych rzeczy, ale one

0:14:50.820,0:14:55.300
Ale z jakiegoś powodu nigdy nie czułem, że  potrafią spełnić oczekiwania.

0:14:55.760,0:15:00.000
Teraz czego nie wiedziałem i nikt kogo ja osobiście znałem też nie wiedział

0:15:00.220,0:15:08.100
że byli naukowcy, którzy 30 lat temu wykazali, żeby uzyskać praktycznie dobre wyniki potrzebujemy więcej warstw neuronów

0:15:08.809,0:15:16.509
Nawet jeśli teoretycznie matematycznie możesz uzyskać tak dokładne, jak chcesz, z tylko jedną dodatkową warstwą, aby to zrobić

0:15:16.970,0:15:24.579
z dobrej wydajnością potrzebujemy więcej warstw. Kiedy dodajemy więcej warstw do sieci neuronowej, otrzymujemy głębokie uczenie

0:15:25.129,0:15:29.918
głębokie nie znaczy niczego mistycznego, tylko oznacza

0:15:30.439,0:15:34.189
więcej warstw. Więcej warstw niż dodanie jednej dodatkowej.

0:15:35.850,0:15:42.200
Dzięki temu sieci neuronowy wykorzystują teraz swój potencjał, tak jak widzieliśmy w tym, w czym dobre jest głębokie uczenie

0:15:42.210,0:15:48.139
Więc możemy teraz powiedzieć, że Rosenblatt miał rację. Mamy maszynę, która jest w stanie

0:15:48.660,0:15:50.220
postrzegać

0:15:50.220,0:15:56.510
rozpoznawać i identyfikować otoczenie bez przeszkolenia lub kontroli człowieka. To jest zdecydowanie prawda

0:15:56.510,0:16:00.229
Nie sądzę, żeby w tym stwierdzeniu opartym na obecnej technologii było coś kontrowersyjnego

0:16:00.990,0:16:02.990
Więc będziemy się uczyć, jak to zrobić

0:16:04.470,0:16:10.730
Będziemy uczyć się, jak to robić w dokładnie odwrotny sposób niż prawdopodobnie wszystkie inne

0:16:11.280,0:16:13.660
matematyczne i techniczne wykształcenie, które mieliście.

0:16:13.860,0:16:18.560
Nie będziemy zaczynali od

0:16:18.750,0:16:25.909
dwugodzinnej lekcji o funkcji sigmoidalnej, lub studiować algebrę liniową lub

0:16:26.820,0:16:28.820
kurs odświeżający o rachunku różniczkowym

0:16:29.250,0:16:31.640
Powodem tego jest to

0:16:33.630,0:16:40.520
Ludzie, którzy uczą się, jak nauczać i uczyć, stwierdzili, że nie jest to odpowiedni sposób dla większości ludzi

0:16:41.220,0:16:43.220
Dla większości ludzi

0:16:44.070,0:16:51.260
My dużo pracujemy na podstawie pracy profesora Davida Perkinsa z Harvardu i innych

0:16:51.540,0:16:54.920
którzy pracują nad podobnymi zagadnieniami i mówi o tym pomyśle

0:16:55.529,0:17:02.419
granie w całą grę. Gra w tę grę jest więc oparta na analogii sportowej, jeśli chcesz nauczyć kogoś bajsebola

0:17:03.450,0:17:05.450
Nie zabierasz ich

0:17:05.670,0:17:11.149
do klasy i zaczynasz uczyć ich o fizyce paraboli

0:17:12.240,0:17:14.240
i jak uszyć piłkę

0:17:15.870,0:17:21.349
i trzyczęściowej historii stuletniej polityki bejsbolowej i dopiero

0:17:21.350,0:17:24.980
dziesięć lat później pozwalasz im oglądać grę, a potem 20 lat później

0:17:24.980,0:17:28.040
pozwalasz im grać, wiesz, to trochę jak

0:17:29.040,0:17:36.199
wygląda edukacja matematyczna. Zamiast tego w bejsbolu, pierwszym krokiem jest: hej, chodźmy obejrzeć bejsbal

0:17:36.870,0:17:39.290
Co myślisz? To było zabawne? Widzisz tam tego faceta?

0:17:39.290,0:17:43.249
Próbuje tam dobiec, zanim ten drugi rzuci tam piłkę. Hej, chcesz spróbować uderzyć?

0:17:43.740,0:17:45.740
Okej, więc uderzysz piłkę i

0:17:46.070,0:17:50.659
ja spróbuję ją złapać, a potem musisz tam pobiec. I tak jest od kroku pierwszego

0:17:50.660,0:17:52.660
Grasz całą grę

0:17:53.100,0:17:58.280
Tak i dodając do tego , gdy ludzie zaczynają, często nie mają całęgo zespołu

0:17:58.660,0:18:00.100
lub nie grają pełnych dziewięciu rund

0:18:00.100,0:18:04.920
Ale nadal mają pojęcie, o tym czym jest ta gra. Taką ogólną wiedzę o grze. Tak

0:18:05.120,0:18:11.700
Jest wiele, wiele powodów dla których to pomaga większości ludzi

0:18:11.920,0:18:13.700
Nie dla wszystkich, tak

0:18:13.960,0:18:17.020
Jest mały procent ludzi,

0:18:17.020,0:18:20.480
którzy lubią budować rzeczy od podstaw i teorii

0:18:20.720,0:18:24.260
i nie dziwne, że są oni w większości w środowiskach uniwersyteckich

0:18:24.270,0:18:28.510
Ponieważ ludzie którzy są naukowcami, dobrze czują się

0:18:28.510,0:18:33.340
z, jak dla mnie, odwróconym do góry nogami sposobem uczenia.

0:18:33.340,0:18:35.660
Ale poza uniwersysteami,

0:18:35.660,0:18:39.400
większość ludzi najlepiej się uczy sposobem góra-dół

0:18:39.860,0:18:42.380
Gdzie zaczynamy od pełnego kontekstu

0:18:42.390,0:18:47.290
Więc krok numer dwa w siedmiu zasadach, i ja tylko zamierzam wspomnieć o pierwszych trzech

0:18:47.290,0:18:49.620
To jest sprawić, że gra jest warta grania

0:18:49.620,0:18:53.590
Co dla gry w bejsbol jest tym ze mamy zawody

0:18:53.590,0:18:57.800
Że, wiecie, zdobywamy punkty, próbujemy wygrać

0:18:58.180,0:19:00.140
Zbieramy się z zespołami z okolic

0:19:00.140,0:19:02.350
i mamy ludzi, którzy chcą się pokonać wzajemnie

0:19:02.350,0:19:07.660
i mamy zestawienie prowadzących, którzy mają największą liczbę 'runs' lub czegokolwiek

0:19:08.720,0:19:14.800
Więc tu chodzi o to żeby mieć pewność, że to co robimy, robimy to właściwie

0:19:14.800,0:19:23.000
Robimy to jako całość, przedstawiamy kontekst i zainteresowanie

0:19:23.000,0:19:30.490
Tak więc, podejście fasai do nauki głębokiego uczenia, oznacza to, że dzisiaj

0:19:30.490,0:19:33.200
będziemy trenować modele od początku do końca.

0:19:33.200,0:19:38.350
Będziemy faktycznie trenować modele i
nie będą to po takie kiepskie modele.

0:19:38.350,0:19:45.060
Będą one najnowocześniejszymi na światowym poziomie
modelami od dzisiaj i możemy spróbować

0:19:45.060,0:19:50.140
żebyście Wy zbudowali swoje własne, światowej klasy modele, dzisiaj lub na następnej lekcji

0:19:50.320,0:19:52.800
w zależności od tego jak się sprawy potoczą

0:19:52.800,0:19:59.200
Następnie numerem trzy w siedmiu zasadach
z Harvardu jest praca z trudnymi częściami

0:19:59.200,0:20:10.050
Co jest w pewnym sensie taką ideą ćwiczeń, przemyślanych ćwiczeń.

0:20:10.050,0:20:19.490
Praca z trudnymi częściami oznacza, że ​ machamy kijem w piłką za każdym razem, tak po prostu

0:20:19.490,0:20:22.320
Wiecie, wychodzicie i po prostu się wygłupiacie

0:20:22.320,0:20:26.500
Trenujecie właściwie, znajdujesz rzecz w ktoerj jesteś najmniej dobry

0:20:26.700,0:20:31.340
znajdujesz miejsca tam gdzie są problemy, cholernie ciężko pracujesz
nad tym.

0:20:31.340,0:20:39.530
Oznacza to, że w kontekście głębokiego uczenia, my nie upraszczamy(ogłupiamy) rzeczy.

0:20:39.530,0:20:40.530
Dobrze

0:20:40.530,0:20:45.210
Do końca kursu to zrobisz
rachunek różniczkowy.

0:20:45.210,0:20:47.400
Zrobisz algebrę liniową.

0:20:47.400,0:20:54.380
Zrobisz inżynierię oprogramowania
kodu, prawda.

0:20:54.380,0:21:04.290
Będziesz ćwiczyć te rzeczy, które
są trudne, więc wymagają wytrwałości i zaangażowania.

0:21:04.290,0:21:11.290
Ale miejmy nadzieję, że zrozumiesz, dlaczego to ma znaczenie
ponieważ zanim zaczniesz coś ćwiczyć

0:21:11.290,0:21:14.470
będziesz wiedzieć, dlaczego potrzebujesz tego, ponieważ będziesz go używać.

0:21:14.470,0:21:19.450
Na przykład gdy chcesz ulepszyć swój model, będziesz musiał najpierw zrozumieć tę koncepcję.

0:21:19.450,0:21:24.490
Więc dla tych, którzy przywykli do tradycyjnego środowiska uczelnianego,
to będzie wyglądało

0:21:24.490,0:21:31.190
dość dziwne i wiele osób mówi, że
żałują, wiesz po roku nauki fastai,

0:21:31.190,0:21:37.560
że spędzili zbyt dużo czasu na nauce
teorii, a za mało czasu na trenowaniu modeli

0:21:37.560,0:21:39.500
i pisaniu kodu.

0:21:39.500,0:21:43.250
Taki jest najczęstrzya informacje zwrotna jaką otrzymujemy od ludzi, którzy mówią:

0:21:43.250,0:21:44.570
Szkoda, że ​​nie zrobiliśmy tego inaczej ”.

0:21:44.570,0:21:45.790
To jest to.

0:21:45.790,0:21:53.080
Dlatego proszę staraj się jak najlepiej potrafisz, ponieważ jesteś tutaj, postępuj zgodnie z tym podejściem.

0:21:53.080,0:21:59.180
Będziemy używać zestawu oprogramowania

0:21:59.460,0:22:00.420
Przepraszam, Rachel, tak

0:22:00.720,0:22:02.500
Potrzebuję tylko powiedzieć coś więcej o tym podejściu.

0:22:02.510,0:22:07.390
Myślę, że odkąd tak wielu z nas spędziło tak wiele lat z tradycyjnym podejściem edukacyjnym od dołu do góry

0:22:07.390,0:22:12.030
że początkowo może to dawać bardzo niewygodne wrażenie

0:22:12.030,0:22:16.620
Ja nadal czasami czuję się z tym niekomfortowo, mimo że jestem oddana temu pomysłowi.

0:22:16.620,0:22:22.660
I, że, też musisz się pilnować i nie mieć nic przeciwko temu, że nie znasz szczegółów.

0:22:22.840,0:22:28.180
Co, jak sądzę, może wydawać się bardzo obce, a nawet błędne, kiedy jesteś w tym nowy.

0:22:28.190,0:22:31.930
Na przykład: „Och, czekaj, używam czegoś i
nie rozumiem wszystkich szczegółów. ”

0:22:31.930,0:22:36.370
Ale w pewnym sensie musisz zaufać, że dojdziemy do tych szczegółów później.

0:22:36.370,0:22:39.560
Więc ja nie mogę Wam współczuć, ponieważ ja nie spędziłem na tym dużo czasu.

0:22:39.560,0:22:44.050
Ale powiem wam - nauczanie w ten sposób
jest bardzo, bardzo, bardzo trudne.

0:22:44.050,0:22:49.430
I bardzo często zdarza mi się wskakiwać z powrotem do podejścia gdzie najpierw zaczynamy od podstaw.

0:22:49.430,0:22:51.810
Ponieważ tak łatwo jest uczyć tak: „Och
musisz to wiedzieć.

0:22:51.810,0:22:52.810
Musisz to wiedzieć.

0:22:52.810,0:22:53.810
Musisz to zrobić.

0:22:53.810,0:22:55.140
I wtedy możesz to wiedzieć. ”

0:22:55.140,0:22:56.540
Ten sposób jest o wiele łatwiejszy do uczenia.

0:22:56.540,0:23:01.760
Więc uważam, że ten sposób jest dużo dużo bardziej trudny do uczenia, ale mam nadzieję, że warto.

0:23:01.760,0:23:06.980
Spędziliśmy dużo czasu zastanawiając się, jak sprowadzić głębokie uczenie do tego formatu.

0:23:06.980,0:23:11.620
Ale jedną z rzeczy, która nam tutaj pomaga,
to oprogramowanie, które mamy dostępne.

0:23:11.620,0:23:23.010
Jeśli wcześniej nie korzystaliście z Pythona - jest to absurdalnie
elastyczny, wyrazisty i łatwy w użyciu język.

0:23:23.010,0:23:28.210
Mamy w nim wiele drobiazgów, których nie lubimy, ale ogólnie rzecz biorąc lubimy go jako całość.

0:23:28.210,0:23:33.790
I uważamy, że to - najważniejsze, że
ogromna, ogromna, ogromna większość 
praktyków i naukowców zajmujących się

0:23:33.790,0:23:38.000
głębokim uczeniem używa Pythona.

0:23:38.000,0:23:41.760
Oprócz Pythona, istnieją dwie biblioteki, z których większość ludzi korzysta dzisiaj:

0:23:41.900,0:23:44.140
PyTorch i TensorFlow.

0:23:44.140,0:23:47.550
Nastąpiła tutaj bardzo szybka zmiana.

0:23:47.550,0:23:51.090
TensorFlow był tym, czego nauczaliśmy jeszcze kilka lat temu.

0:23:51.090,0:23:54.970
Wszyscy go używali jeszcze kilka lat temu

0:23:54.970,0:24:00.370
TensorFlow utknął w martwym punkcie. W zasadzie TensorFlow utknął w martwym punkcie.

0:24:00.370,0:24:05.930
Pojawiło się inne oprogramowanie o nazwie PyTorch, które było o wiele łatwiejsze w użyciu i o wiele bardziej

0:24:05.930,0:24:15.040
przydatne dla naukowców i w ostatnich
12 miesiącach, odsetek artykułów naukowych na głównych

0:24:15.040,0:24:21.290
konferencjach, które korzystają z PyTorch, wzrósł z 20% do 80% i na odwrót, ci, którzy używają

0:24:21.290,0:24:24.960
TensorFlow zmalało z 80% do 20%.

0:24:24.960,0:24:29.030
Więc w zasadzie wszyscy ludzie, którzy są w zasadzie tworzą technologię, z której wszyscy korzystamy,

0:24:29.030,0:24:35.340
teraz używają PyTorch-a i wiesz, branża zmienia się nieco wolniej, ale w następnym roku lub

0:24:35.340,0:24:38.900
dwóch prawdopodobnie zobaczysz podobną rzecz w branży.

0:24:38.900,0:24:45.180
W PyTorch chodzi o to, że jest bardzo
bardzo elastyczny i naprawdę jest zaprojekowany do

0:24:45.180,0:24:52.570
elastyczności i łatwości programowania, napewno nie jest zaprojektowany dla początkujących

0:24:52.570,0:24:57.950
I nie jest przeznaczony do tego, co nazywamy, nie ma interfejsu API wyższego poziomu, tu mam na myśli

0:24:57.950,0:25:05.630
że nie ma środków tak naprawdę do zbudowania rzeczy szybko za pomocą PyTorch.

0:25:05.630,0:25:13.700
Aby poradzić sobie z tym problemem, mamy bibliotekę zwaną fastai, która znajduje się powyżej PyTorch-a.

0:25:13.700,0:25:20.330
Fastai jest najpopularniejszym API wyższego poziomu dla PyTorch-a.

0:25:20.330,0:25:27.520
Ponieważ nasze kursy są tak popularne,
niektórzy ludzie mają błędne wrażenie

0:25:27.520,0:25:34.260
że fastai jest zaprojektowane dla początkujących lub do nauczania.

0:25:34.260,0:25:43.840
Jest przeznaczona dla początkujących i nauczania, a także praktyków w przemyśle i badaczy.

0:25:43.840,0:25:50.290
Sposób, w jaki to robimy, zapewnia, że ​​jest
to najlepszy interfejs API dla wszystkich tych osób

0:25:50.290,0:25:59.340
ponieważ używamy czegoś co się nazywa warstwowym API. I jest recenzowana praca, którą Sylvain

0:25:59.340,0:26:04.600
i ja napisaliśmy, w której opisaliśmy, jak to zrobiliśmy. I a dla tych z was, którzy są inżynierami oprogramowania,

0:26:04.600,0:26:08.130
nie będzie to wcale niezwykłe ani zaskakujące.

0:26:08.130,0:26:12.590
To po prostu całkowicie standardowe praktyki inżynierii oprogramowania, ale są to praktyki, które

0:26:12.590,0:26:17.030
nie występowały w żadnej bibliotece do głębokiego uczenia, które widzieliśmy.

0:26:17.030,0:26:24.500
Zasadniczo po prostu dużo refaktoryzacji i oddzielania, a więc stosując to podejście, pozwoliło nam

0:26:24.500,0:26:32.410
zbudować coś, co możesz użyć do super badań niskiego poziomu, możesz zrobić najnowocześniejsze

0:26:32.410,0:26:43.850
modele produkcyjne i możesz zrobić coś super łatwego, dla początkujących, ale modele światowej klasy początkujących.

0:26:43.850,0:26:47.220
To jest podstawowy zesetaw oprogramowania. Bedą też inne elementy oprogramowania, których będziemy się uczyć

0:26:47.220,0:26:49.940
po drodze.

0:26:49.940,0:26:54.570
Ale, myślę, że to najważniejsze, i chcę o tym wspomnieć, że to właściwie nie ma znaczenia.

0:26:54.570,0:27:01.300
Jeśli nauczysz się tego zestawu oprogramowania, a następnie
w pracy będziesz używać TensorFlow i Keras,

0:27:01.300,0:27:06.380
będziesz mógł się przestawić w krócej niż
tydzień.

0:27:06.380,0:27:13.070
Wielu studentów tak zrobiło,
to nigdy nie było problemem.

0:27:13.070,0:27:20.700
Ważne jest, aby nauczyć się podstaw
dlatego skupimy się na tych pojęciach

0:27:20.700,0:27:27.870
i za pomocą interfejsu API, który minimalizuje ilość 'boilerplate', które musisz użyć, to znaczy, że Ty

0:27:27.870,0:27:29.730
możesz skupić się na ważnych rzeczach.

0:27:29.730,0:27:38.150
Rzeczywiste wiersze kodu będą dużo bardziej odpowiadać do faktycznych koncepcji, które wdrażasz.

0:27:38.150,0:27:41.450
Będziecie potrzebowali maszyny z GPU.

0:27:41.450,0:27:49.420
GPU to jednostka przetwarzania grafiki, a konkretnie
potrzebujesz procesora graficznego Nvidia.

0:27:49.420,0:27:55.520
Inne marki GPU po prostu nie są dobrze obsługiwane
przez biblioteki do głębokiego uczenia.

0:27:55.520,0:27:56.970
Proszę ich nie kupować..

0:27:56.970,0:28:00.130
Jeśli już to macie, prawdopodobnie nie powinniście tego używać.

0:28:00.130,0:28:05.400
Zamiast tego powinniście użyć jednej z platform, które dla Was przygotowaliśmy.

0:28:05.400,0:28:10.410
To jest ogromne rozproszenie, spędzanie czasu na robienie rzeczy jak, administracja systemu

0:28:10.410,0:28:16.330
na komputerze z procesorem graficznym i instalowaniem sterowników oraz
bla bla bla.

0:28:16.330,0:28:18.000
I używaj go w systemie Linux.

0:28:18.000,0:28:19.000
Proszę.

0:28:19.000,0:28:22.260
Tak robią wszyscy, nie tylko my,
wszyscy używają go w systemie Linux.

0:28:22.260,0:28:23.370
Ułatw sobie życie.

0:28:23.370,0:28:28.200
Jest wystarczająco trudno nauczyć się głębokiego uczenia bez
robienie tego w sposób, w którym uczysz się

0:28:28.200,0:28:31.550
wiesz, wszystkiego rodzaju problemów związanych ze sprzętem.

0:28:31.550,0:28:43.480
Dostępnych jest wiele bezpłatnych opcji i
więc proszę, proszę skorzystaj z nich.

0:28:43.480,0:28:48.280
Jeśli korzystasz z opcji, która nie jest darmowa, nie zapomnij wyłączyć instancji.

0:28:48.280,0:28:51.730
Więc co się stanie. Będziesz
uruchamiać serwer, który znajduję się gdzieś

0:28:51.730,0:28:57.260
indziej  na świecie, a ty się połączysz do niego ze swego komputera i będziesz trenował

0:28:57.260,0:29:01.500
uruchamiał i budował modele.

0:29:01.500,0:29:05.980
Tylko dlatego, że zamkniesz okno przeglądarki, nie oznacza, że ​​serwer przestaje pracować

0:29:06.980,0:29:07.980
Dobrze.

0:29:07.980,0:29:11.330
Więc nie zapomnij go wyłączyć, bo inaczej będziesz płacić za to.

0:29:11.330,0:29:16.120
Colab, to świetny system, który jest bezpłatny.

0:29:16.120,0:29:18.650
Istnieje również wersja płatnej subskrypcji
tego.

0:29:18.650,0:29:21.200
Ostrożnie z Colabem.

0:29:21.200,0:29:26.590
Większość innych systemów, które zalecamy, zapisuje Twoja prace automatycznie i możesz

0:29:26.590,0:29:28.460
wróć do tego w dowolnym momencie.

0:29:28.460,0:29:29.460
Colab nie.

0:29:29.460,0:29:37.110
Więc koniecznie sprawdź wątek o platformie Colab na forach, aby się o tym dowiedzieć.

0:29:37.110,0:29:44.020
Wspominam więc o forach ...

0:29:44.020,0:29:51.970
Fora są naprawdę bardzo bardzo ważne, ponieważ tam właśnie odbywa się cała dyskusja i konfiguracja

0:29:51.970,0:29:54.030
i wszystko inne się dzieje.

0:29:54.030,0:29:56.240
Na przykład, jeśli potrzebujesz pomocy z konfiguracją, tutaj

0:29:56.240,0:30:03.820
Wiesz, jest wątek pomocy konfiguracji i
możesz dowiedzieć się, jak najlepiej ustawić Colab

0:30:03.820,0:30:09.150
i możesz zobaczyć dyskusje na temat, i możesz zadawać pytania i proszę pamiętaj

0:30:09.150,0:30:12.310
szukać, zanim zadasz pytanie, prawda.






0:40:01.849,0:40:04.259
Więc pomysł jest taki.

0:40:04.259,0:40:10.480
To jest właściwie ta wersja, z którą chcesz eksperymentować.

0:40:10.480,0:40:15.170
Ponieważ zmusza cię ona do myślenia o tym, co się dzieje na każdym kroku

0:40:15.170,0:40:18.799
a nie tylko do czytania i uruchamiania go bez zastanowienia.

0:40:18.799,0:40:24.059
Chcemy, żebyś robił to w małym, nagim środowisku, w którym myślisz jak o tym

0:40:24.059,0:40:28.859
co mówiła książka, dlaczego tak się dzieje i jeśli o czymś zapomnisz

0:40:28.859,0:40:31.321
to wracasz do książki.

0:40:31.321,0:40:36.910
Inną rzeczą, o której należy wspomnieć jest zarówno kurs w wersji V4, jak i `fastbook` wersja książkowa

0:40:36.910,0:40:42.000
na końcu mają pytania.

0:40:42.000,0:40:46.529
I sporo osób powiedziało nam, że wiesz, że wśród recenzentów, że

0:40:46.529,0:40:49.990
oni tak naprawdę przeczytali te pytania na początku.

0:40:49.990,0:40:57.869
Spędziliśmy wiele, wiele tygodni pisząc te pytania, Sylvain i ja.

0:40:57.869,0:41:04.380
A powód tego jest taki, że staramy się myśleć o tym, co chcemy, abyś

0:41:04.380,0:41:07.680
zapamiętał z każdego notatnika.

0:41:07.680,0:41:10.029
Więc jeśli przeczytasz pytania na początku

0:41:10.029,0:41:12.150
Dowiesz się które rzeczy my uważamy za istotne.

0:41:12.150,0:41:14.940
Które rzeczy powinniście wiedzieć zanim przejdziesz dalej

0:41:14.940,0:41:20.040
Więc zamiast mieć podsumowanie na końcu, które mówi, że powinieneś wiedzieć, blah blah blah,

0:41:20.360,0:41:23.660
W zamian tego mamy pytania, które spełniają to samo zadanie.

0:41:23.960,0:41:27.720
Więc proszę pamiętaj żeby odpowiedzieć na pytania zanim przejdziesz do następnego roździału.

0:41:27.720,0:41:31.600
Nie musisz odpowiedzieć poprawnie na wszystkie pytania i w większości odpowiadanie na pytania

0:41:31.600,0:41:37.999
jest tak proste jak powrót do tej częsci notatnika i przeczytania tekstu

0:41:38.000,0:41:44.460
ale jeśli coś przeoczyłeś, wróć i przeczytaj to, bo to są rzeczy, któe zakładamy, że znasz.

0:41:44.960,0:41:50.420
Więc jeśli nie opanowaliści tych rzeczy zanim przejdziecie dalej, może to być frustrujące.

0:41:50.420,0:41:57.499
Jednakże, jeżeli utkniecie mimo tego żę próbowaliście kilka razy, przejdźcie do  następnego rozdziału,

0:41:57.499,0:42:00.809
Zrób dwa lub trzy rozdziały a potem wróć.

0:42:00.809,0:42:05.300
może do czasu, gdy zrobisz jeszcze kilka rozdziałów, wiesz, będziesz miał trochę więcej perspektywy.

0:42:05.480,0:42:10.540
Staramy się wyjaśniać rzeczy wielokrotnie na różne sposoby, so it's okay if you tried

0:42:10.840,0:42:14.140
więc nie ma problemu, jeśli spróbujesz i utkniesz

0:42:14.140,0:42:17.320
wtedy możesz iść dalej.

0:42:21.120,0:42:26.400
W porządku, więc spróbujmy uruchomić pierwszą część notatnika.

0:42:26.400,0:42:37.480
Więc tutaj jesteśmy w 01 intro, więc to jest to rozdział 1 i tutaj jest nasza pierwsza komórka.

0:42:37.480,0:42:46.280
Więc klikam na komórkę i domyślnie, faktycznie, będzie tam nagłówek na pasku narzędzi, jak widać.

0:42:46.480,0:42:47.480
Można go włączać i wyłączać

0:42:47.481,0:42:53.640
Ja zawsze go zostawiam. Więc aby uruchomić tą komórkę, można albo klinknąć na 'play'

0:42:53.640,0:42:56.940
przycisk uruchamiania lub jak wspomniałem, można nacisnąć 'shift' 'enter'

0:42:56.940,0:43:04.100
Więc dla tego jednego to po prostu klikam i jak widać ta gwiazda pojawia się, więc to mówi, że jest uruchomiona

0:43:04.500,0:43:08.780
a teraz możesz zobaczyć, jak wyskakuje pasek postępu, który zajmie kilka sekund

0:43:09.080,0:43:15.680
i jak się wykonuje będzie wyświetlał wyniki

0:43:15.680,0:43:18.740
Nie oczekuj, że uzyskasz dokładnie takie same wyniki jak my

0:43:19.020,0:43:23.779
jest pewna przypadkowość związana z trenowaniem modelu, i to jest w porządku.

0:43:23.780,0:43:26.530
Nie oczekuj, że uzyskasz dokładnie takie same czasy, jak my.

0:43:26.530,0:43:33.360
Jeśli ta pierwsza komórka zajmuje więcej niż pięć minut, chyba że masz naprawdę stary procesor graficzny, to jest prawdopodobnie złym znakiem.

0:43:33.500,0:43:38.600
Możesz wejść na forum i dowiedzieć się, co się dzieje.

0:43:38.609,0:43:43.400
a może używasz Windows, który w tej chwili naprawdę nie działają zbyt dobrze.

0:43:43.400,0:43:45.210
Nie martw się, że nie wiemy jeszcze, co robi cały ten kod.

0:43:45.210,0:43:49.680
Staramy się tylko o to, żebyśmy mogli wytrenować model.

0:43:50.300,0:43:52.300
Więc oto jesteśmy, skończyło się wykonywać.

0:43:52.400,0:43:56.420
i jak widzisz, zostało wydrukowane kilka informacji.

0:43:56.700,0:44:05.260
i w tym przypadku pokazuje mi to, że jest poziom błędu 0,005 przy robieniu czegoś.

0:44:05.269,0:44:06.569
Co to coś robi?

0:44:06.569,0:44:14.089
Cóż, to co tu robi, to tak naprawdę pobiera zestaw danych, nazywamy go zestawem danych o zwierzętach domowych (pets dataset)

0:44:14.089,0:44:18.849
który jest zestawem danych ze zdjęciami kotów i psów

0:44:18.849,0:44:25.829
I próbuje się dowiedzieć, które z nich są kotami, a które psami.

0:44:25.829,0:44:34.560
I jak widać, po mniej niż minucie jest w stanie to zrobić z błędem 0,5%

0:44:34.800,0:44:37.039
Więc może to zrobić całkiem idealnie.

0:44:37.039,0:44:39.509
Więc wytrenowaliśmy nasz pierwszy model

0:44:39.509,0:44:40.539
Nie mamy pojęcia jak

0:44:40.539,0:44:41.799
Nie wiemy, co robiliśmy

0:44:41.799,0:44:44.259
Ale rzeczywiście wytrenowaliśmy nasz model

0:44:44.259,0:44:46.559
Więc to dobry początek

0:44:46.559,0:44:51.309
I jak widzisz, możemy trenować modele dość szybko na jednym komputerze.

0:44:51.309,0:44:55.089
Który wiecie - Wiele z nich można używać za darmo

0:44:55.089,0:45:00.869
Jeszcze jedna rzecz, o której należy wspomnieć, jeśli masz Mac-a - nie ma znaczenia, czy masz Windows

0:45:00.869,0:45:05.069
Mac czy Linux, jeśli chodzi o to, co jest uruchamiane w przeglądarce

0:45:05.069,0:45:11.470
Ale jeśli masz Maca, proszę nie próbuj używać tego układu GPU

0:45:11.470,0:45:16.150
Tak naprawdę Mac - Apple nie obsługuje już nawet procesorów graficznych Nvidia

0:45:16.150,0:45:19.470
Więc to naprawdę nie będzie świetna opcja

0:45:19.470,0:45:20.869
Więc trzymaj się Linuksa.

0:45:20.869,0:45:25.010
Dzięki temu życie stanie się dla Ciebie dużo łatwiejsze

0:45:25.010,0:45:30.420
Racja, tak naprawdę pierwszą rzeczą, którą powinniśmy zrobić, jest wypróbowanie tego

0:45:30.420,0:45:34.750
Więc jeśli - twierdzę, że wytrenowaliśmy model, który potrafi odróżniać koty od psów

0:45:34.750,0:45:37.640
Upewnijmy się, że możemy

0:45:37.640,0:45:41.859
Więc sprawdźmy tę komórkę

0:45:41.860,0:45:42.860
To jest interesujące, prawda

0:45:43.100,0:45:47.940
Stworzyliśmy obiekt `widgets.FileUpload` i wyświetliliśmy go

0:45:47.940,0:45:50.690
A to faktycznie pokazuje nam przycisk, który możemy kliknąć

0:45:50.690,0:45:52.619
Więc jak wspomniałem, to jest niezwykły REPL

0:45:52.619,0:45:55.319
Możemy nawet stworzyć GUI, w tym REPL

0:45:55.319,0:45:58.359
Więc jeśli kliknę na ten `file upload`

0:45:58.359,0:46:00.170
I mogę wybrać 'kot'

0:46:00.170,0:46:04.130
Proszę bardzo

0:46:04.130,0:46:11.230
I mogę teraz zamienić te przesłane dane w obrazek

0:46:11.230,0:46:14.319
To jest kot

0:46:14.320,0:46:19.200
I teraz mogę użyć predykcji `predict`

0:46:19.200,0:46:21.200
i to jest kot

0:46:21.500,0:46:26.400
Z prawdopodobieństwem 99,96%

0:46:26.400,0:46:29.910
Więc widzimy, że właśnie wgraliśmy obraz, który wybraliśmy

0:46:29.910,0:46:30.930
Więc powinniście tego spróbować

0:46:30.930,0:46:31.930
Dobrze

0:46:31.930,0:46:32.930
Weź zdjęcie kota

0:46:32.930,0:46:35.579
Znajdź zdjęcie z Internetu albo sam zrób zdjęcie

0:46:35.579,0:46:38.910
I upewnij się, że dostaniesz zdjęcie kota

0:46:38.910,0:46:43.520
To jest coś, co może rozpoznać zdjęcia kotów, a nie rysunki kreskowe kotów

0:46:43.520,0:46:46.940
I tak jak zobaczymy, w tym kursie

0:46:46.940,0:46:52.050
Tego rodzaju modele mogą się uczyć tylko z tych informacji, które im przekazujesz

0:46:52.050,0:46:57.130
A jak na razie podaliśmy tylko, jak się dowiesz, zdjęcia kotów

0:46:57.130,0:47:06.700
Nie koty anime, nie koty rysunkowe, nie abstrakcyjne przedstawienia kotów, tylko zdjęcia

0:47:06.700,0:47:11.470
Więc teraz przyjrzymy się, co tu się właściwie wydarzyło

0:47:11.470,0:47:15.930
I zobaczysz w tej chwili, nie dostaję tu żadnych wielkich informacji

0:47:15.930,0:47:26.259
Jeśli widzisz to, w swoich notatnikach, będziesz musiał zrobić: `File -> Trust Notebook`

0:47:26.259,0:47:30.559
I to tylko mówi Jupyter-owi, że może uruchomić kod niezbędny do wyświetlania rzeczy

0:47:30.559,0:47:33.509
aby upewnić się, że nie ma żadnych problemów z bezpieczeństwem

0:47:33.509,0:47:35.880
I tak teraz zobaczysz wynik

0:47:35.880,0:47:39.880
Czasami widzisz jakiś dziwny kod, jak ten

0:47:39.880,0:47:43.609
To jest kod który w zasadzie tworzy wyniki

0:47:43.609,0:47:46.349
Więc czasami ukrywamy ten kod

0:47:46.349,0:47:47.800
Czasami go pokazujemy

0:47:47.800,0:47:52.560
Więc ogólnie rzecz biorąc, można po prostu zignorować takie rzeczy i skupić się na tym, co wychodzi

0:47:52.940,0:47:54.300
Więc nie zamierzam przez to przechodzić

0:47:54.300,0:48:00.660
Zamiast tego przyjrzę się temu - to samo tutaj, na slajdach

0:48:00.660,0:48:04.710
Więc to, co tu robimy to jest uczenie maszynowe

0:48:04.710,0:48:07.750
Głębokie uczenie jest rodzajem uczenia maszynowego

0:48:07.750,0:48:09.170
Czym jest uczenie maszynowe?

0:48:09.170,0:48:16.070
Uczenie się maszynowe jest, tak jak zwykłe programowanie, sposobem na sprawienie , by komputery coś zrobiły.

0:48:16.070,0:48:21.140
Ale w tym przypadku dość trudno jest zrozumieć, w jaki sposób można wykorzystać zwykłe programowanie

0:48:21.320,0:48:24.000
do rozpoznawania zdjęć psów od kotów

0:48:24.000,0:48:28.319
W jaki sposób tworzysz pętle i zmienne przypisania oraz warunki

0:48:28.319,0:48:31.789
do tworzenia programu, który rozpoznaje psy i koty na zdjęciach

0:48:31.789,0:48:33.190
To jest bardzo trudne

0:48:33.190,0:48:34.589
Bardzo bardzo trudne

0:48:34.589,0:48:41.420
Tak trudne, że do czasów ery głębokiego uczenia, nikt tak naprawdę nie miał modelu, który byłby wystarczająco dokładny w tym niby łatwym zadaniu

0:48:41.420,0:48:43.910
w tym niby łatwym zadaniu

0:48:43.910,0:48:46.970
Bo nie możemy zapisać niezbędnych kroków

0:48:46.970,0:48:51.369
Więc normalnie, wiesz, zapisujemy funkcję, która pobiera niektóre wejścia i przechodzi przez nasz

0:48:51.369,0:48:52.369
program

0:48:52.369,0:48:55.569
Generuje pewne wyniki

0:48:55.569,0:49:02.530
Tak więc ten ogólny pomysł, gdzie program jest czymś, gdzie zapisujemy kroki

0:49:02.530,0:49:06.970
Nie wydaje się, żeby to było dobre dla takich rzeczy jak rozpoznawanie obrazów

0:49:06.970,0:49:12.470
Tak więc już w 1949 roku, ktoś o nazwisku Arthur Samuel zaczął próbować znaleźć sposób na rozwiązanie

0:49:12.470,0:49:16.030
problemów, takich jak rozpoznawanie zdjęć kotów i psów

0:49:16.030,0:49:23.000
A w 1962 roku opisał sposób, w jaki można to zrobić

0:49:23.000,0:49:26.270
Otóż najpierw opisał problem: "Zaprogramowanie komputera do tego typu

0:49:26.270,0:49:31.070
obliczeń jest w najlepszym wypadku trudnym zadaniem

0:49:31.070,0:49:37.589
Ze względu na konieczność opisania każdego pojedynczego kroku procesu w irytujących szczegółach

0:49:37.589,0:49:42.290
Komputery są gigantycznymi kretynami, co wszyscy z nas, programistów, całkowicie rozpoznają."

0:49:42.290,0:49:46.769
Powiedział więc, okay, nie mówmy komputerowi o dokładnych krokach, ale podajmy mu przykłady

0:49:46.769,0:49:50.460
problemu do rozwiązania i dowiedzmy się, jak on sam go rozwiąże

0:49:50.460,0:49:56.269
I tak, w 1961 roku zbudował program do gry w warcaby, który pokonał mistrza stanu Connecticut

0:49:56.269,0:50:03.450
nie mówiąc mu, jakie kroki należy podjąć, aby grać w warcaby, ale zamiast tego, to, czym jest:

0:50:03.450,0:50:09.990
"zorganizować automatyczny sposób badania skuteczności przypisania wag

0:50:09.990,0:50:15.690
pod względem rzeczywistej wydajności oraz mechanizm zmiany przypisania wag w celu

0:50:15.690,0:50:19.019
zmaksymalizowania wydajności"

0:50:19.019,0:50:21.680
To zdanie jest kluczowe

0:50:21.680,0:50:24.440
I jest to dość podchwytliwe zdanie, więc możesz spędzić nad nim trochę czasu

0:50:24.440,0:50:32.200
Podstawową ideą jest to, że zamiast mówić wejścia do programu, a następnie wyjścia

0:50:32.200,0:50:36.430
Mamy dane wejściowe do - nazwijmy program teraz modelem

0:50:36.430,0:50:38.140
To jest ta sama podstawowa idea

0:50:38.140,0:50:40.349
Wejścia do modelu i wyniki

0:50:40.349,0:50:43.760
I wtedy będziemy mieli drugą rzecz zwaną wagami

0:50:43.760,0:50:50.569
I tak podstawowa idea jest taka, że model ten jest czymś, co wytwarza wyniki nie tylko na podstawie

0:50:50.569,0:50:58.410
na przykład, stanu szachownicy, ale także w oparciu o jakiś zestaw wag lub parametrów

0:50:58.410,0:51:02.320
które opisują, jak ten model będzie działać

0:51:02.320,0:51:09.039
Chodzi więc o to, że gdybyśmy mogli wymienić wszystkie możliwe sposoby gry w warcaby

0:51:09.040,0:51:15.640
a następnie opisać każdy z tych sposobów za pomocą jakiegoś zestawu parametrów lub tego, co Samuel nazywał wagami.

0:51:15.820,0:51:22.600
Następnie, gdybyśmy mieli sposób na sprawdzenie, jak skuteczne jest bieżące przypisanie wagi w odniesieniu do rzeczywistych wyników

0:51:22.800,0:51:29.760
innymi słowy, czy to konkretne określenie strategii gry w warcaby kończy się wygraniem lub przegraniem gry

0:51:29.760,0:51:35.400
a następnie sposób na zmianę przypisania wagi tak, aby zmaksymalizować wyniki

0:51:35.600,0:51:40.710
Więc spróbujmy zwiększyć lub zmniejszyć każdą z tych wag pojedynczo

0:51:40.710,0:51:44.220
aby dowiedzieć się, czy istnieje nieco lepszy sposób gry w warcaby

0:51:44.480,0:51:50.880
a następnie zrobić to wiele razy, po czym na końcu taka procedura mogłaby być całkowicie zautomatyzowana

0:51:51.220,0:51:55.400
i wtedy tak zaprogramowana maszyna nauczyłaby się ze swojego doświadczenia

0:51:55.520,0:52:00.200
więc ten mały akapit jest, jest sednem problemu

0:52:00.200,0:52:01.620
To jest uczenie maszynowe

0:52:01.880,0:52:11.340
sposób tworzenia programów tak, aby się uczyły, a nie były programowane

0:52:11.340,0:52:16.860
więc gdybyśmy mieli coś takiego, to w zasadzie mielibyśmy teraz coś, co wygląda jak to

0:52:17.000,0:52:23.240
masz dane wejściowe i wagi jeszcze raz, wychodzące do modelu, tworząc wyniki, tzn. wygrałeś lub przegrałeś

0:52:23.500,0:52:26.760
a następnie pomiar skuteczności.

0:52:26.760,0:52:30.840
Więc pamiętaj, że to był ten kluczowy krok, a potem drugi kluczowy krok to sposób na aktualizację wag

0:52:31.080,0:52:35.600
w oparciu o zmierzone wyniki, a następnie można przejść w pętli przez ten proces

0:52:35.609,0:52:43.450
i stworzyć, wytrenować model uczenia maszynowego, więc to jest abstrakcyjny pogląd

0:52:43.450,0:52:49.260
Więc po pewnym czasie, prawda, pojawił się zestaw wag, które są dość dobre

0:52:49.260,0:52:55.089
Dobrze, możemy teraz zapomnieć o sposobie, w jaki był trenowany i mamy coś

0:52:55.089,0:53:02.359
co jest właśnie takie, prawda, z wyjątkiem słowa program, które jest teraz zastąpione przez słowo model

0:53:02.359,0:53:07.239
Tak więc wytrenowany model może być używany jak każdy inny program komputerowy

0:53:07.239,0:53:13.509
Tak więc pomysł jest taki, że budujemy program komputerowy nie poprzez definiowanie niezbędnych kroków

0:53:13.509,0:53:20.600
do wykonania zadania, ale poprzez trenowanie go tak, aby nauczył się wykonywać zadanie, na końcu którego jest tylko kolejnym programem

0:53:20.840,0:53:31.200
a więc to, co nazywa się wnioskowaniem (inference) dobrze jest to używanie wytrenowanego modelu jako programu do wykonywania zadań takich jak granie w warcaby

0:53:33.320,0:53:42.980
Tak więc uczenie maszynowe jest trenowaniem programów stworzonych poprzez umożliwienie komputerowi uczenia się na podstawie jego doświadczeń, a nie poprzez ręczne kodowanie

0:53:46.000,0:53:53.640
Dobrze, jak to zrobić dla rozpoznawania obrazów, jaki jest ten model i jaki zestaw wag

0:53:53.640,0:53:59.700
taki, że jak je zmieniamy, może stawać się coraz lepszy w rozpoznawaniu kotów i psów

0:53:59.700,0:54:02.210
To znaczy w warcabach

0:54:02.210,0:54:05.240
Nietrudno sobie wyobrazić, jak można by to wyliczyć

0:54:05.500,0:54:12.100
w zależności od tego, jak bardzo pionek przeciwnika jest oddalony od twojego pionka, co powinieneś zrobić w tej sytuacji

0:54:12.280,0:54:16.079
Jak powinieneś rozważyć strategie obronne kontra agresywne, bla bla bla.

0:54:16.079,0:54:20.410
Wcale nie jest to oczywiste, jak się to robi dla rozpoznawania obrazu.

0:54:20.410,0:54:29.240
Tak więc to, czego naprawdę chcemy, to jakaś funkcja, która jest tak elastyczna,

0:54:29.240,0:54:33.210
że istnieje zestaw wag, które mogą spowodować, że zrobi wszystko.

0:54:33.210,0:54:37.960
Prawdziwa - jak najbardziej elastyczna z możliwych funkcji na świecie

0:54:38.280,0:54:41.059
i okazuje się, że coś takiego istnieje

0:54:41.059,0:54:44.140
To jest sieć neuronowa

0:54:44.140,0:54:50.329
Więc opiszemy dokładnie czym jest ta matematyczna funkcja na kolejnych lekcjach

0:54:50.329,0:54:56.160
Aby jej użyć, tak naprawdę nie ma znaczenia co to jest tą funkcją matematyczną

0:54:56.160,0:55:02.320
Jest to funkcja, o której mówimy, że jest "sparametryzowana" przez jakiś zestaw wag

0:55:02.540,0:55:08.880
przez co rozumiem, że kiedy daję jej inny zestaw wag, wykonuje ona inne zadanie

0:55:09.300,0:55:16.540
i faktycznie może wykonać każde możliwe zadanie: coś, co nazywamy twierdzeniem o uniwersalnej zbieżności

0:55:16.540,0:55:26.320
mówi nam, że matematycznie sprawdzalna forma funkcjonalna może rozwiązać każdy problem, który można rozwiązać na dowolnym poziomie dokładności

0:55:26.320,0:55:28.589
Jeśli tylko znajdziesz odpowiedni zestaw wag

0:55:28.589,0:55:35.580
Co jest rodzajem powtórzenia tego, co opisaliśmy wcześniej w tym, jak mamy do czynienia z problemem Minsky-ego (Marvin Minsky)

0:55:35.580,0:55:40.700
Więc sieci neuronowe są tak elastyczne, że jeżeli znajdziesz odpowiedni zestaw wag

0:55:40.980,0:55:45.860
mogą rozwiązać każdy problem, w tym "Czy to kot, czy to pies"

0:55:46.280,0:55:50.020
Oznacza to, że musisz skoncentrować swój wysiłek na procesie ich trenowania

0:55:50.340,0:55:57.000
czyli na znalezieniu dobrych wag, dobrych przypisań wag, aby używać terminologii Samuela

0:55:57.010,0:55:59.770
Więc jak to robisz?

0:55:59.770,0:56:09.239
Chcemy, aby to zrobić w całkowicie ogólny sposób - zaktualizować wagi w oparciu o pewną miarę wydajności

0:56:09.239,0:56:14.200
np. jak dobre jest rozpoznawanie kotów w porównaniu z psami

0:56:14.200,0:56:16.839
I na szczęście okazuje się, że coś takiego istnieje!

0:56:16.839,0:56:21.539
A ta rzecz nazywa się stochastycznym gradientem prostym (lub SGD).

0:56:21.540,0:56:26.240
Jeszcze raz przyjrzymy się dokładnie jak to działa, sami zbudujemy to od podstaw

0:56:26.380,0:56:28.520
ale na razie nie musimy się tym martwić.

0:56:28.520,0:56:34.980
Powiem wam jednak, że ani SGD, ani sieci neuronowe nie są wcale skomplikowane matematycznie.

0:56:35.200,0:56:38.820
Prawie w całości są one dodawaniem i mnożeniem.

0:56:38.820,0:56:46.000
Sztuczka polega na tym, że jest ich tylko ogromna ilość - jak miliardy - tak wiele więcej, niż jesteśmy w stanie intuicyjnie pojąć.

0:56:46.100,0:56:52.940
Potrafią robić niezwykle potężne rzeczy, ale nie są wcale czymś skomplikowanym.

0:56:52.940,0:56:58.609
Nie są rzeczami skomplikowanymi i zobaczymy dokładnie, jak działają.

0:56:58.609,0:57:03.049
Więc to jest wersja Arthura Samuela, prawda.

0:57:03.049,0:57:08.580
Obecnie nie używamy tej samej terminologii, ale używamy dokładnie tej samej idei.

0:57:08.580,0:57:14.300
Więc tę funkcję, która znajduje się w środku, nazywamy architekturą.

0:57:14.540,0:57:20.779
Architektura to funkcja, z którą dostosowujemy wagi, żeby coś wykonać

0:57:20.779,0:57:24.190
To jest architektura, to jest funkcjonalna forma modelu

0:57:24.190,0:57:28.849
Czasami ludzie mówią, że model oznacza architekturę, więc nie pozwól, aby to zbytnio cię zmyliło

0:57:28.849,0:57:30.559
Ale naprawdę właściwym słowem jest architektura

0:57:30.559,0:57:34.619
Nie nazywamy ich wagami, nazywamy je parametrami

0:57:34.619,0:57:40.410
Wagi mają konkretne znaczenie - to dość szczególny rodzaj parametru

0:57:40.410,0:57:49.420
Rzeczy, które wychodzą z modelu, architektura z parametrami, nazywamy ich przewidywaniami

0:57:49.800,0:57:53.020
Przewidywania opierają się na dwóch rodzajach danych wejściowych

0:57:53.320,0:57:57.960
niezależnych zmiennych, czyli danych, takich jak zdjęcia kotów i psów

0:57:58.220,0:58:03.300
oraz zmiennych zależnych, zwanych też etykietami

0:58:03.300,0:58:08.060
czyli takich, które mówią "to jest kot", "to jest pies", "to jest kot"

0:58:08.400,0:58:09.779
Więc, to są twoje dane wejściowe

0:58:09.779,0:58:12.769
Więc, wyniki są przewidywaniami

0:58:12.769,0:58:18.670
Miarą wydajności, używając słowa Arthura Samuela, jest strata

0:58:18.670,0:58:23.280
Tak więc, strata jest obliczana na podstawie etykiet na przewidywaniach

0:58:23.440,0:58:26.720
 a następnie jest aktualizowana z powrotem do parametrów

0:58:26.720,0:58:33.980
Okay, więc, to jest ten sam obraz, który widzieliśmy, ale używając słów, z których korzystamy dzisiaj

0:58:34.200,0:58:40.020
Tak więc, ten obrazek - jeśli zapomnisz, jeśli powiem, że są to parametry wykorzystane w tej architekturze

0:58:40.039,0:58:44.220
do stworzenia modelu - możesz wrócić i przypomnieć sobie, co one oznaczają

0:58:44.220,0:58:45.220
Czym są te parametry?

0:58:45.220,0:58:46.500
Czym są przewidywania?

0:58:46.500,0:58:47.500
Czym jest strata?

0:58:47.500,0:58:52.580
Okay, strata jakiejś funkcji, która mierzy wydajność modelu

0:58:52.900,0:58:56.780
w taki sposób, że możemy aktualizować parametry

0:58:56.790,0:59:06.170
Tak więc, należy zauważyć, że głębokie uczenie i uczenie maszynowe nie są magią, prawda?

0:59:06.170,0:59:14.580
Model może być stworzony tylko wtedy, gdy posiadasz dane pokazujące przykłady rzeczy, o których próbujesz się nauczyć. 

0:59:14.860,0:59:21.820
Może on nauczyć się tylko operować na wzorcach, które widziałeś w danych wejściowych używanych do jego trenowania, prawda?

0:59:22.020,0:59:27.100
Tak więc, jeśli nie mamy żadnych rysunków kreskowych kotów i psów, to nigdy nie będzie

0:59:27.100,0:59:34.200
aktualizacji parametrów, które sprawiają, że architektura, a więc architektura i parametry razem są modelem

0:59:34.420,0:59:40.100
Tak więc, mówiąc o modelu, która sprawia, że model lepiej przewiduje rysunki kotów i psów

0:59:40.100,0:59:46.420
ponieważ po prostu, nigdy nie otrzymał tych aktualizacji wag, ponieważ nigdy nie otrzymał tych danych wejściowych

0:59:46.680,0:59:51.239
Zauważ również, że to podejście do uczenia zawsze tworzy tylko przewidywania

0:59:51.239,0:59:54.319
Nie mówi ci ono, co masz z tym zrobić

0:59:54.319,0:59:58.019
To będzie bardzo ważne, gdy będziemy myśleć o takich rzeczach jak system rekomendacji

0:59:58.019,1:00:01.230
w stylu "jaki produkt komuś polecamy"?

1:00:01.230,1:00:04.950
Cóż, nie wiem... Nie robimy tego, prawda?

1:00:04.950,1:00:10.940
Możemy przewidzieć, co ktoś powie o produkcie, który mu pokazaliśmy, ale nie tworzymy akcji

1:00:11.140,1:00:12.310
Tworzymy przewidywania

1:00:12.310,1:00:16.619
To bardzo ważna różnica do rozpoznania

1:00:16.619,1:00:22.470
Nie wystarczy tylko mieć przykłady danych wejściowych, jak zdjęcia psów i kotów