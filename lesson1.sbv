0:00.219,0:00:05.399
Cześć wszystkim i witamy na pierwszej lekcji głębokiego uczenia dla programistów

0:00:06.129,0:00:08.129
To jest czwarty

0:00:08.170,0:00:10.439
rok, w którym prowadzimy ten kurs

0:00:11.230,0:00:12.820
Ale jest on

0:00:12.820,0:00:14.820
bardzo różny i bardzo

0:00:14.920,0:00:16.150
specjalny

0:00:16.150,0:00:19.559
z wielu powodów. Pierwszym powodem jest to, że

0:00:19.840,0:00:26.219
nadajemy go na żywo w pierwszym dniu całkowitego zamknięcia lub niepełnego zamknięcia

0:00:26.220,0:00:28.349
Ale prawie całkowitego zamknięcie w San Francisco

0:00:29.050,0:00:34.050
Będziemy go nagrywać w ciągu najbliższych dwóch miesięcy w trakcie tej globalnej epidemii

0:00:34.050,0:00:41.399
Więc jeżeli czasami ten kurs wydaje się trochę szalony, przepraszam, ale właśnie dlatego tak się dzieje.

0:00:42.940,0:00:47.160
Innym powodem, dla którego ten kurs jest wyjątkowy, jest to, że

0:00:49.090,0:00:52.889
Staramy się, aby była to nasza ostateczna wersja, prawda.

0:00:53.949,0:00:55.840
Odkąd prowadzimy ten kurs już od jakiegoś czasu

0:00:55.840,0:01:00.329
W końcu doszliśmy do punktu, w którym prawie czujemy, że wiemy, o czym mówimy

0:01:00.940,0:01:05.129
Do tego stopnia, że Sylvain i ja napisaliśmy książkę

0:01:05.650,0:01:08.999
I napisaliśmy oprogramowanie od zera

0:01:09.369,0:01:14.849
Nazywające się biblioteką fastai w wersji 2. Napisaliśmy recenzowany artykuł o tej bibliotece

0:01:16.450,0:01:22.830
Więc jest to coś w rodzaju wersji kursu

0:01:24.070,0:01:26.070
który będzie służył nam przez długi czas

0:01:27.250,0:01:31.650
Program kursu oparty jest bardzo ściśle na tej książce, prawda.

0:01:31.810,0:01:36.060
Więc jeśli chcesz ją czytać razem z kursem

0:01:37.030,0:01:38.320
Proszę, kup ją

0:01:38.320,0:01:43.349
i mówię, proszę, kup ją, bo tak naprawdę cała książka jest dostępna za darmo w

0:01:43.869,0:01:47.578
formie notatników Jupiter Notebooks, a to dzięki

0:01:48.159,0:01:49.479
olbrzymiej

0:01:49.479,0:01:53.188
hojności wydawnictwa O'Reilly, które nam na to pozwoliło

0:01:54.159,0:01:55.810
więc

0:01:55.810,0:01:57.159
dobrze

0:01:57.159,0:02:01.618
Będziecie mogli zobaczyć na stronie kursu, jak dostać dostęp do tego wszystkiego

0:02:02.920,0:02:04.920
ale

0:02:05.380,0:02:09.810
Oto repozytorium książki "fastbook", gdzie możecie przeczytać tą całą cholerną rzecz

0:02:12.040,0:02:14.730
W tej chwili, jak widzicie, jest to wersja wstępna, ale do czasu

0:02:15.489,0:02:17.489
jak to zobaczycie, już nie będzie

0:02:18.040,0:02:21.030
Więc mamy tutaj wielką prośbę

0:02:21.879,0:02:23.110
um

0:02:23.110,0:02:25.110
Umowa jest taka

0:02:25.300,0:02:29.039
Możecie czytać to ją za darmo jako notatniki Jupyter Notebooks, ale

0:02:30.010,0:02:35.910
to nie jest tak wygodne, jak czytanie jej na Kindle lub wiesz w książce papierowej lub czymkolwiek

0:02:35.920,0:02:41.250
Więc proszę, nie przekształcajcie jej w plik PDF, prawda. Proszę, nie zmieniajcie jej w

0:02:42.240,0:02:44.240
formę przeznaczona bardziej do czytania

0:02:44.940,0:02:50.700
Ponieważ w pewnym sensie chodzi o to, że mamy nadzieję, że wiesz, że kupisz ją dobrze, nie nie

0:02:51.580,0:02:53.920
wykorzystujcie hojności O'Reilly

0:02:54.549,0:02:56.019
przez

0:02:56.019,0:02:58.019
tworzenie rzecz, którą

0:02:58.030,0:03:05.099
Wiesz, nie dają ci za darmo. I to jest wyraźnie licencja, na podstawie której my również ją udostępniamy

0:03:05.099,0:03:07.099
Więc jest coś, wiesz

0:03:07.150,0:03:09.450
Jest to głównie prośba o bycie porządnym człowiekiem

0:03:10.060,0:03:15.119
Jeśli widzicie, że ktoś inny nie jest przyzwoitym człowiekiem i kradnie książkową wersję książki

0:03:15.120,0:03:19.679
Powiedzcie im, proszę, nie róbcie tego. To nie jest miłe i nie bądźcie takimi osobami

0:03:21.010,0:03:26.970
Tak czy inaczej możecie czytać wraz z programem zawartym w książce

0:03:28.480,0:03:35.190
Istnieje kilka różnych wersji tych notatników, prawda, jest tam

0:03:38.049,0:03:41.578
Tam jest pełny notatnik

0:03:43.030,0:03:48.509
Który ma całą prozę, zdjęcia, wszystko. My napisaliśmy

0:03:50.200,0:03:57.569
system, który zamienia notatniki w drukowaną książkę, a czasem wygląda to trochę dziwnie, na przykład

0:03:58.510,0:04:03.480
tutaj jest dziwnie wyglądająca tabela i jeśli zajrzycie do prawdziwej książki

0:04:05.019,0:04:11.459
Wtedy wygląda jak właściwa tabla. Więc czasami zobaczysz trochę dziwnych kawałków

0:04:11.459,0:04:17.939
Okej, to nie pomyłki. Są to fragmenty, w których dodajemy informacje, które pomogą nam zmienić tą książkę we właściwą fajną książkę

0:04:17.940,0:04:19.940
Więc po prostu je zignoruj

0:04:25.570,0:04:28.749
jedną ważna część nas jest

0:04:29.660,0:04:35.860
Sylvain. Sylvain jest moim współautorem książki i biblioteki fastai w wersji 2.

0:04:35.860,0:04:38.139
Więc jest on moim partnerem w zbrodni

0:04:39.190,0:04:41.090
drugim kluczowym

0:04:41.090,0:04:43.090
my tutaj

0:04:43.640,0:04:49.990
Jest Rachel Thomas, a więc może Rachel, możesz przyjść i przywitać się. Jest ona współzałożycielką fast.ai.

0:04:53.510,0:04:55.749
Witam, jestem współzałożycielem fast.ai.

0:04:56.780,0:05:04.630
Niżej. Przepraszam, jestem wyższa niż Jeremy, i jestem dyrektorem założycielem Centre for applied data ethics na Uniwersytecie w San Francisco

0:05:05.360,0:05:10.599
Jestem naprawdę podekscytowana uczestnictwem w tym kursie i będę głosem, który usłyszycie który czyta pytania zadawane na forach

0:05:15.050,0:05:20.979
Rachel i Sylvain są również ludźmi z tej grupy, którzy faktycznie rozumieją matematykę. Ja jestem zwykłym absolwentem filozofii

0:05:21.830,0:05:26.319
Rachel ma doktorat, Silvain napisał 10 książek o matematyce. Więc

0:05:26.900,0:05:29.799
Jeśli pojawią się pytania matematyczne, to mogę

0:05:30.320,0:05:32.320
Przekazać je do nich

0:05:32.330,0:05:37.059
Ale bardzo miło jest mieć możliwość pracy z ludźmi, którzy rozumieją ten temat tak dobrze

0:05:38.360,0:05:40.419
Tak. Tak, Rachel. Chciałeś

0:05:41.990,0:05:48.069
Jasne, dziękuję. Jak Rachel wspomniała, drugim obszarem, w którym ona jest

0:05:49.400,0:05:56.199
Wiesz, ma prawdziwą wiedzę światowej klasy to etyka danych. Jest dyrektorem założycielem Center for Applied Data Ethics

0:06:00.230,0:06:02.230
Na Uniwersytecie w San Francisco. Dziękuję Ci

0:06:02.720,0:06:09.279
Przez cały kurs będziemy rozmawiać o etyce danych, ponieważ uważamy to za bardzo ważne

0:06:09.890,0:06:15.490
Tak więc te części, chociaż ogólnie je przedstawię. Będą one w całości oparte na

0:06:16.400,0:06:17.570
pracy Rachel.

0:06:17.570,0:06:20.110
Ponieważ ona wie o czym mówi

0:06:21.470,0:06:24.460
Chociaż dzięki niej. Ja też trochę  wiem o tym, o czym mówię.

0:06:25.760,0:06:27.760
Racja, więc to tyle

0:06:31.040,0:06:37.420
Więc, czy powinniście tu być? Czy jest jakiś punkt, który próbujesz zrozumieć?

0:06:40.549,0:06:42.549
Zrozumieć w głębokim uczeniu

0:06:44.719,0:06:52.719
Okej, więc co, wiesz co, czy powinniście tu być? Czy jest jakiś punkt, którego próbujesz nauczyć się w głębokim uczeniu. Czy jesteś

0:06:53.539,0:07:00.998
Zbyt głupi, albo nie masz wystarczającej ilości ogromnych zasobów, czy cokolwiek innego, ponieważ tak mówi nam wiele osób

0:07:00.999,0:07:06.368
Mówią, że potrzebujesz zespołów doktorów i ogromnych centrów danych pełnych GPU. Inaczej

0:07:06.889,0:07:08.889
To nie ma sensu

0:07:09.199,0:07:15.338
Nie martw się. To wcale nie jest prawda. To nie może być dalsze od prawdy. W rzeczywistości ogroma większść

0:07:17.629,0:07:19.629
Wieke światowej klasy

0:07:19.669,0:07:26.378
badań i światowej klasy projektów przemysłówych wywodzi się od absolwentów fastai i

0:07:27.709,0:07:29.709
fastai

0:07:30.139,0:07:34.179
Projektów opartych na bibliotece fastai i gdzie indziej

0:07:35.239,0:07:37.239
Które zostały utworzone na jednym GPU

0:07:37.459,0:07:38.719
za pomocą

0:07:38.719,0:07:44.469
kilkudziesięciu lub kilkuset punktów danych przez osóby, które nie mają

0:07:45.559,0:07:46.969
doświadczenia technicznego na poziomie wyższego wykształcenia

0:07:46.969,0:07:53.859
lub w moim przypadku, ja nie mam specjalistycznej wiedzy technicznej na poziomie licencjackim. Jestem po prostu filozofem z wykształcenia

0:07:54.619,0:07:56.599
więc tam jest

0:07:56.599,0:07:58.089
I zobaczymy to w trakcie kursu

0:07:58.089,0:08:03.099
Ale jest wiele, wiele empirycznych dowodów na to, że nie potrzebujesz dużo matematyki

0:08:03.099,0:08:08.259
Nie potrzebujesz dużo danych. Nie potrzebujesz wielu drogich komputerów, aby robić świetne rzeczy z głębokim uczeniem. Więc

0:08:08.989,0:08:10.989
Po prostu się z nami trzymaj. Będzie dobrze.

0:08:11.779,0:08:13.779
Aby skończyć ten kurs, potrzebujesz kodować

0:08:15.469,0:08:17.469
Najlepiej gdy wiesz, jak kodować w Pythonie

0:08:18.259,0:08:19.989
ale jeśli znasz inne języki

0:08:19.989,0:08:21.989
Możesz nauczyć się Python-a

0:08:22.069,0:08:28.208
Jeśli jedynymi językami, w których programowałeś, jest coś podobnego do MATLAB, gdzie używałeś go bardziej jak języka skryptowego

0:08:28.939,0:08:31.629
Może to być dla Ciebie trochę. Będzie to dla Ciebie trochę cięższe

0:08:32.990,0:08:37.419
Ale to dobrze, kontynuuj. Możesz uczyć się języka Python w trakcie

0:08:40.399,0:08:44.318
Czy uczenie się głębokiego uczenia ma sens, czy jest ono w czymś dobre?

0:08:44.930,0:08:48.729
Jeśli masz nadzieję zbudować mózg

0:08:49.699,0:08:51.559
któy jest AGI

0:08:51.559,0:08:59.229
Nie mogę obiecać, że ci w tym pomożemy, a AGI oznacza ogólną sztuczną inteligencję. Dziękuję Ci

0:09:00.130,0:09:03.520
Mogę Ci jednak powiedzieć, że we wszystkich tych obszarach.

0:09:04.130,0:09:10.900
Głębokie uczenie jest najlepszym rozwiązaniem do, co najmniej do wielu wersji wszystkich tych rzeczy

0:09:12.290,0:09:13.850
więc jest to

0:09:13.850,0:09:17.740
W tym momencie nie spekuluje się, czy jest to przydatne narzędzie

0:09:17.740,0:09:24.609
Jest to przydatne narzędzie w wielu, wielu miejscach, niezwykle przydatnych narzędzie. I w wielu tych przypadków

0:09:25.580,0:09:31.449
jest równoważne lub lepsze niż ludzka wydajność przynajmniej według pewnego szczególnego rodzaju zawężenia

0:09:31.820,0:09:35.020
definicji rzeczy, które ludzie robią w tego rodzaju obszarach.

0:09:35.780,0:09:38.379
Tak głębokie uczenie się jest niesamowite

0:09:38.390,0:09:39.260
i jeśli

0:09:39.260,0:09:44.830
chcesz zatrzymać wideo tutaj, przejrzeć i spróbować wybrać kilka rzeczy, które Twoim zdaniem

0:09:44.830,0:09:52.330
wyglądają ciekawie, i wpisz to słowo kluczowe i głębokie uczenie w Google, a znajdziesz wiele artykułów, przykładów i tego typu rzeczy

0:09:54.860,0:09:56.390
Głębokie uczenie

0:09:56.390,0:10:02.559
wywodzi się z sieci neuronowych. Jak  zobaczycie, głębokie uczenie się typem

0:10:03.770,0:10:05.770
uczenia sieci neuronowych, a dokładniej głębokiego.

0:10:06.170,0:10:12.640
Później wyjaśnie co to znaczy. Sieci neuronowe z pewnością nie są niczym nowym. Pracowano nad nimi przynajmniej do

0:10:13.250,0:10:15.250
od 1943, kiedy McCulloch i Pitts

0:10:15.560,0:10:22.239
Stworzyli model matematyczny sztucznego neuronu i bardzo się podekscytowali, doczego to może doprowadić

0:10:23.020,0:10:25.020
A potem w latach 50

0:10:25.840,0:10:27.620
Frank Rosenblatt

0:10:27.620,0:10:29.620
zbudował na podstawie tego

0:10:30.220,0:10:34.900
Zasadniczo on wprowadził subtelne zmiany w tym modelu matematycznym

0:10:35.540,0:10:41.409
I pomyślał, że dzięki tym subtelnym zmianom możemy być świadkami narodzin maszyny zdolnej do postrzegania

0:10:41.780,0:10:46.089
rozpoznawanie i identyfikowanie otoczenia bez przeszkolenia lub kontroli człowieka oraz

0:10:46.640,0:10:48.939
nadzorował on budowę tej

0:10:49.910,0:10:54.040
niezwykłej rzeczy, perceptronu mark 1 w Cornell

0:10:56.270,0:10:58.749
Myślę, że to było, to zdjęcie było z 1961 roku

0:11:00.050,0:11:06.820
Na szczęście w dzisiejszych czasach, nie musimy budować sieci neuronowych, prowadząc te cholerne druty od neurona do neurona, od sztucznego neurona do sztucznego neurona

0:11:07.070,0:11:09.309
ale możecie zobaczyć tą pomysł

0:11:09.410,0:11:14.200
Jest tu dużo połączeń. Na tym kursie często będziemy slyszeli słowo „połączenie”, bo o to w tym wszystkim chodzi

0:11:16.570,0:11:20.109
Potem mieliśmy pierwszą zimę SI, tak to nazywano, która naprawdę

0:11:20.840,0:11:25.299
w dużym stopniu zaistniała z powodu profesora MIT o nazwisku Marvin Minsky

0:11:26.000,0:11:33.520
A Papert napisał książkę o nazwie "Perceptrony" o wynalazku Rosenblatta, w której wskazali, że jedna warstwa

0:11:33.950,0:11:35.060
tych

0:11:35.060,0:11:37.060
sztucznych urządzeń neuronowych

0:11:37.280,0:11:39.080
właściwie nie mogłą się nauczyć

0:11:39.080,0:11:44.979
niektóreych kluczowe rzeczy. Było to dla niej niemożliwe do nauczenia się czegoś tak prostego, jak logiczny operator XOR

0:11:46.340,0:11:51.309
W tej samej książce wykazali, że użycie wielu warstw urządzeń faktycznie rozwiązałoby problem

0:11:51.980,0:11:55.930
ludzie zignorowali to, nie zauważyli tej części książki i tylko zauważyli

0:11:57.020,0:12:01.299
ograniczenia i ludzie w zasadzie zdecydowali, że sieci neuronowe do niczego nie doprowadzą

0:12:02.090,0:12:03.320
i

0:12:03.320,0:12:05.859
w dużej mierze one zniknęły na dziesięciolecia

0:12:06.500,0:12:07.910
aż do

0:12:07.910,0:12:10.690
W pewnym sensie do 1986 r. Wiele się również wydarzyło do tego czsu

0:12:11.390,0:12:14.169
ale w 1986 roku było coś wielkiego

0:12:14.900,0:12:21.309
MIT wydało książkę, serię dwóch tomów książki, pod tytułem "Równoległe przetwarzanie rozproszone"

0:12:23.240,0:12:26.740
W którym opisali tę rzecz, nazwaną przetwarzaniem równoległym rozproszonym

0:12:27.320,0:12:32.559
gdzie mamy kilka jednostek przetwarzających, które mają pewien stan aktywacji

0:12:32.960,0:12:37.040
i jakąś funkcję wyjściową i jakiś wzór połączeń

0:12:37.340,0:12:43.680
i jakieś zasady propagacyjne oraz jakieś zasady aktywacyjne i jakieś reguły uczenia działające w środowisku

0:12:43.960,0:12:47.640
A potem opisali, jak rzeczy któe spełniają te wymagania

0:12:48.500,0:12:52.900
Teoretycznie mogą wykonywać wiele niesamowitych prac

0:12:52.900,0:12:54.999
Był to wynik wielu

0:12:55.280,0:13:02.619
naukowców pracujących razem. Cała grupa była zaangażowani w ten projekt, który zaowocował tą bardzo ważną książką

0:13:03.080,0:13:09.909
Ciekawe jest dla mnie to, że jeśli ukończysz ten kurs, wróć i spójrz

0:13:10.280,0:13:18.219
na to zdjęcie, a zobaczysz, że robimy dokładnie te rzeczy, Wszystko czego się uczymy naprawdę jest, jak robimy

0:13:18.830,0:13:20.720
każdą z tych

0:13:20.720,0:13:25.959
ośmiu rzeczy. W porządku. I ciekawe jest, że obejmują one środowisko, ponieważ jest to coś, co bardzo często

0:13:26.720,0:13:31.509
ignorowane przez naukowców zajmujących się danych. To znaczy budujesz model, wytrenowałeś go,  on sie nauczył czegoś

0:13:31.509,0:13:37.269
W jakim kontekście działa. I my mówimy o tym również przez kilka następnych lekcji.

0:13:39.619,0:13:41.619
W latach 80

0:13:42.379,0:13:48.459
W trakcie i po tym, jak to zostało wydane, ludzie zaczęli budować w tej drugiej warstwie neuronów

0:13:48.859,0:13:52.329
unikając problemu Minsky'ego

0:13:53.179,0:13:55.179
I pokazano

0:13:55.880,0:14:02.080
I udowodniono matematycznie, że dodając jedną dodatkową warstwę neuronów było wystarczające na to by pozwolić

0:14:02.620,0:14:08.380
aby każdy moodel matematyczny był przybliżony do dowolnego poziomu dokładności za pomocą tych sieci neuronowych

0:14:09.320,0:14:13.600
I to było dokładnie odwrotne do problemu Minsky'ego

0:14:13.600,0:14:18.850
To było jak: hej, wiesz, nie ma nic, czego nie możemy zrobić, ewidentnie nie ma nic czego nie da się zrobić

0:14:18.850,0:14:22.080
I to było w czasie kiedy ja zaczęłam się angażować w sieci neuronowe

0:14:23.040,0:14:28.280
Ja zacząłem trochę później, wyydaje mi się. Ja zacząłęm angażować się w późnych latach 90.

0:14:28.840,0:14:34.880
I były one bardzo szeroko stosowane w przemyśle. Używałem ich do bardzo nudnych rzeczy, takich jak ukierunkowany marketing dla banków detalicznych

0:14:35.980,0:14:39.280
zwykle były to duże firmy z dużą ilością pieniędzy, które z nich korzystały z nich

0:14:39.640,0:14:46.660
Często sieci były zbyt duże lub zbyt wolne, aby były przydatne.

0:14:47.140,0:14:50.820
Z pewnością były przydatne do niektórych rzeczy, ale one

0:14:50.820,0:14:55.300
Ale z jakiegoś powodu nigdy nie czułem, że  potrafią spełnić oczekiwania.

0:14:55.760,0:15:00.000
Teraz czego nie wiedziałem i nikt kogo ja osobiście znałem też nie wiedział

0:15:00.220,0:15:08.100
że byli naukowcy, którzy 30 lat temu wykazali, żeby uzyskać praktycznie dobre wyniki potrzebujemy więcej warstw neuronów

0:15:08.809,0:15:16.509
Nawet jeśli teoretycznie matematycznie możesz uzyskać tak dokładne, jak chcesz, z tylko jedną dodatkową warstwą, aby to zrobić

0:15:16.970,0:15:24.579
z dobrej wydajnością potrzebujemy więcej warstw. Kiedy dodajemy więcej warstw do sieci neuronowej, otrzymujemy głębokie uczenie

0:15:25.129,0:15:29.918
głębokie nie znaczy niczego mistycznego, tylko oznacza

0:15:30.439,0:15:34.189
więcej warstw. Więcej warstw niż dodanie jednej dodatkowej.

0:15:35.850,0:15:42.200
Dzięki temu sieci neuronowy wykorzystują teraz swój potencjał, tak jak widzieliśmy w tym, w czym dobre jest głębokie uczenie

0:15:42.210,0:15:48.139
Więc możemy teraz powiedzieć, że Rosenblatt miał rację. Mamy maszynę, która jest w stanie

0:15:48.660,0:15:50.220
postrzegać

0:15:50.220,0:15:56.510
rozpoznawać i identyfikować otoczenie bez przeszkolenia lub kontroli człowieka. To jest zdecydowanie prawda

0:15:56.510,0:16:00.229
Nie sądzę, żeby w tym stwierdzeniu opartym na obecnej technologii było coś kontrowersyjnego

0:16:00.990,0:16:02.990
Więc będziemy się uczyć, jak to zrobić

0:16:04.470,0:16:10.730
Będziemy uczyć się, jak to robić w dokładnie odwrotny sposób niż prawdopodobnie wszystkie inne

0:16:11.280,0:16:13.660
matematyczne i techniczne wykształcenie, które mieliście.

0:16:13.860,0:16:18.560
Nie będziemy zaczynali od

0:16:18.750,0:16:25.909
dwugodzinnej lekcji o funkcji sigmoidalnej, lub studiować algebrę liniową lub

0:16:26.820,0:16:28.820
kurs odświeżający o rachunku różniczkowym

0:16:29.250,0:16:31.640
Powodem tego jest to

0:16:33.630,0:16:40.520
Ludzie, którzy uczą się, jak nauczać i uczyć, stwierdzili, że nie jest to odpowiedni sposób dla większości ludzi

0:16:41.220,0:16:43.220
Dla większości ludzi

0:16:44.070,0:16:51.260
My dużo pracujemy na podstawie pracy profesora Davida Perkinsa z Harvardu i innych

0:16:51.540,0:16:54.920
którzy pracują nad podobnymi zagadnieniami i mówi o tym pomyśle

0:16:55.529,0:17:02.419
granie w całą grę. Gra w tę grę jest więc oparta na analogii sportowej, jeśli chcesz nauczyć kogoś bajsebola

0:17:03.450,0:17:05.450
Nie zabierasz ich

0:17:05.670,0:17:11.149
do klasy i zaczynasz uczyć ich o fizyce paraboli

0:17:12.240,0:17:14.240
i jak uszyć piłkę

0:17:15.870,0:17:21.349
i trzyczęściowej historii stuletniej polityki bejsbolowej i dopiero

0:17:21.350,0:17:24.980
dziesięć lat później pozwalasz im oglądać grę, a potem 20 lat później

0:17:24.980,0:17:28.040
pozwalasz im grać, wiesz, to trochę jak

0:17:29.040,0:17:36.199
wygląda edukacja matematyczna. Zamiast tego w bejsbolu, pierwszym krokiem jest: hej, chodźmy obejrzeć bejsbal

0:17:36.870,0:17:39.290
Co myślisz? To było zabawne? Widzisz tam tego faceta?

0:17:39.290,0:17:43.249
Próbuje tam dobiec, zanim ten drugi rzuci tam piłkę. Hej, chcesz spróbować uderzyć?

0:17:43.740,0:17:45.740
Okej, więc uderzysz piłkę i

0:17:46.070,0:17:50.659
ja spróbuję ją złapać, a potem musisz tam pobiec. I tak jest od kroku pierwszego

0:17:50.660,0:17:52.660
Grasz całą grę

0:17:53.100,0:17:58.280
Tak i dodając do tego , gdy ludzie zaczynają, często nie mają całęgo zespołu

0:17:58.660,0:18:00.100
lub nie grają pełnych dziewięciu rund

0:18:00.100,0:18:04.920
Ale nadal mają pojęcie, o tym czym jest ta gra. Taką ogólną wiedzę o grze. Tak

0:18:05.120,0:18:11.700
Jest wiele, wiele powodów dla których to pomaga większości ludzi

0:18:11.920,0:18:13.700
Nie dla wszystkich, tak

0:18:13.960,0:18:17.020
Jest mały procent ludzi,

0:18:17.020,0:18:20.480
którzy lubią budować rzeczy od podstaw i teorii

0:18:20.720,0:18:24.260
i nie dziwne, że są oni w większości w środowiskach uniwersyteckich

0:18:24.270,0:18:28.510
Ponieważ ludzie którzy są naukowcami, dobrze czują się

0:18:28.510,0:18:33.340
z, jak dla mnie, odwróconym do góry nogami sposobem uczenia.

0:18:33.340,0:18:35.660
Ale poza uniwersysteami,

0:18:35.660,0:18:39.400
większość ludzi najlepiej się uczy sposobem góra-dół

0:18:39.860,0:18:42.380
Gdzie zaczynamy od pełnego kontekstu

0:18:42.390,0:18:47.290
Więc krok numer dwa w siedmiu zasadach, i ja tylko zamierzam wspomnieć o pierwszych trzech

0:18:47.290,0:18:49.620
To jest sprawić, że gra jest warta grania

0:18:49.620,0:18:53.590
Co dla gry w bejsbol jest tym ze mamy zawody

0:18:53.590,0:18:57.800
Że, wiecie, zdobywamy punkty, próbujemy wygrać

0:18:58.180,0:19:00.140
Zbieramy się z zespołami z okolic

0:19:00.140,0:19:02.350
i mamy ludzi, którzy chcą się pokonać wzajemnie

0:19:02.350,0:19:07.660
i mamy zestawienie prowadzących, którzy mają największą liczbę 'runs' lub czegokolwiek

0:19:08.720,0:19:14.800
Więc tu chodzi o to żeby mieć pewność, że to co robimy, robimy to właściwie

0:19:14.800,0:19:23.000
Robimy to jako całość, przedstawiamy kontekst i zainteresowanie

0:19:23.000,0:19:30.490
Tak więc, podejście fasai do nauki głębokiego uczenia, oznacza to, że dzisiaj

0:19:30.490,0:19:33.200
będziemy trenować modele od początku do końca.

0:19:33.200,0:19:38.350
Będziemy faktycznie trenować modele i
nie będą to po takie kiepskie modele.

0:19:38.350,0:19:45.060
Będą one najnowocześniejszymi na światowym poziomie
modelami od dzisiaj i możemy spróbować

0:19:45.060,0:19:50.140
żebyście Wy zbudowali swoje własne, światowej klasy modele, dzisiaj lub na następnej lekcji

0:19:50.320,0:19:52.800
w zależności od tego jak się sprawy potoczą

0:19:52.800,0:19:59.200
Następnie numerem trzy w siedmiu zasadach
z Harvardu jest praca z trudnymi częściami

0:19:59.200,0:20:10.050
Co jest w pewnym sensie taką ideą ćwiczeń, przemyślanych ćwiczeń.

0:20:10.050,0:20:19.490
Praca z trudnymi częściami oznacza, że  machamy kijem w piłką za każdym razem, tak po prostu

0:20:19.490,0:20:22.320
Wiecie, wychodzicie i po prostu się wygłupiacie

0:20:22.320,0:20:26.500
Trenujecie właściwie, znajdujesz rzecz w ktoerj jesteś najmniej dobry

0:20:26.700,0:20:31.340
znajdujesz miejsca tam gdzie są problemy, cholernie ciężko pracujesz
nad tym.

0:20:31.340,0:20:39.530
Oznacza to, że w kontekście głębokiego uczenia, my nie upraszczamy(ogłupiamy) rzeczy.

0:20:39.530,0:20:40.530
Dobrze

0:20:40.530,0:20:45.210
Do końca kursu to zrobisz
rachunek różniczkowy.

0:20:45.210,0:20:47.400
Zrobisz algebrę liniową.

0:20:47.400,0:20:54.380
Zrobisz inżynierię oprogramowania
kodu, prawda.

0:20:54.380,0:21:04.290
Będziesz ćwiczyć te rzeczy, które
są trudne, więc wymagają wytrwałości i zaangażowania.

0:21:04.290,0:21:11.290
Ale miejmy nadzieję, że zrozumiesz, dlaczego to ma znaczenie
ponieważ zanim zaczniesz coś ćwiczyć

0:21:11.290,0:21:14.470
będziesz wiedzieć, dlaczego potrzebujesz tego, ponieważ będziesz go używać.

0:21:14.470,0:21:19.450
Na przykład gdy chcesz ulepszyć swój model, będziesz musiał najpierw zrozumieć tę koncepcję.

0:21:19.450,0:21:24.490
Więc dla tych, którzy przywykli do tradycyjnego środowiska uczelnianego,
to będzie wyglądało

0:21:24.490,0:21:31.190
dość dziwne i wiele osób mówi, że
żałują, wiesz po roku nauki fastai,

0:21:31.190,0:21:37.560
że spędzili zbyt dużo czasu na nauce
teorii, a za mało czasu na trenowaniu modeli

0:21:37.560,0:21:39.500
i pisaniu kodu.

0:21:39.500,0:21:43.250
Taki jest najczęstrzya informacje zwrotna jaką otrzymujemy od ludzi, którzy mówią:

0:21:43.250,0:21:44.570
Szkoda, że nie zrobiliśmy tego inaczej ”.

0:21:44.570,0:21:45.790
To jest to.

0:21:45.790,0:21:53.080
Dlatego proszę staraj się jak najlepiej potrafisz, ponieważ jesteś tutaj, postępuj zgodnie z tym podejściem.

0:21:53.080,0:21:59.180
Będziemy używać zestawu oprogramowania

0:21:59.460,0:22:00.420
Przepraszam, Rachel, tak

0:22:00.720,0:22:02.500
Potrzebuję tylko powiedzieć coś więcej o tym podejściu.

0:22:02.510,0:22:07.390
Myślę, że odkąd tak wielu z nas spędziło tak wiele lat z tradycyjnym podejściem edukacyjnym od dołu do góry

0:22:07.390,0:22:12.030
że początkowo może to dawać bardzo niewygodne wrażenie

0:22:12.030,0:22:16.620
Ja nadal czasami czuję się z tym niekomfortowo, mimo że jestem oddana temu pomysłowi.

0:22:16.620,0:22:22.660
I, że, też musisz się pilnować i nie mieć nic przeciwko temu, że nie znasz szczegółów.

0:22:22.840,0:22:28.180
Co, jak sądzę, może wydawać się bardzo obce, a nawet błędne, kiedy jesteś w tym nowy.

0:22:28.190,0:22:31.930
Na przykład: „Och, czekaj, używam czegoś i
nie rozumiem wszystkich szczegółów. ”

0:22:31.930,0:22:36.370
Ale w pewnym sensie musisz zaufać, że dojdziemy do tych szczegółów później.

0:22:36.370,0:22:39.560
Więc ja nie mogę Wam współczuć, ponieważ ja nie spędziłem na tym dużo czasu.

0:22:39.560,0:22:44.050
Ale powiem wam - nauczanie w ten sposób
jest bardzo, bardzo, bardzo trudne.

0:22:44.050,0:22:49.430
I bardzo często zdarza mi się wskakiwać z powrotem do podejścia gdzie najpierw zaczynamy od podstaw.

0:22:49.430,0:22:51.810
Ponieważ tak łatwo jest uczyć tak: „Och
musisz to wiedzieć.

0:22:51.810,0:22:52.810
Musisz to wiedzieć.

0:22:52.810,0:22:53.810
Musisz to zrobić.

0:22:53.810,0:22:55.140
I wtedy możesz to wiedzieć. ”

0:22:55.140,0:22:56.540
Ten sposób jest o wiele łatwiejszy do uczenia.

0:22:56.540,0:23:01.760
Więc uważam, że ten sposób jest dużo dużo bardziej trudny do uczenia, ale mam nadzieję, że warto.

0:23:01.760,0:23:06.980
Spędziliśmy dużo czasu zastanawiając się, jak sprowadzić głębokie uczenie do tego formatu.

0:23:06.980,0:23:11.620
Ale jedną z rzeczy, która nam tutaj pomaga,
to oprogramowanie, które mamy dostępne.

0:23:11.620,0:23:23.010
Jeśli wcześniej nie korzystaliście z Pythona - jest to absurdalnie
elastyczny, wyrazisty i łatwy w użyciu język.

0:23:23.010,0:23:28.210
Mamy w nim wiele drobiazgów, których nie lubimy, ale ogólnie rzecz biorąc lubimy go jako całość.

0:23:28.210,0:23:33.790
I uważamy, że to - najważniejsze, że
ogromna, ogromna, ogromna większość 
praktyków i naukowców zajmujących się

0:23:33.790,0:23:38.000
głębokim uczeniem używa Pythona.

0:23:38.000,0:23:41.760
Oprócz Pythona, istnieją dwie biblioteki, z których większość ludzi korzysta dzisiaj:

0:23:41.900,0:23:44.140
PyTorch i TensorFlow.

0:23:44.140,0:23:47.550
Nastąpiła tutaj bardzo szybka zmiana.

0:23:47.550,0:23:51.090
TensorFlow był tym, czego nauczaliśmy jeszcze kilka lat temu.

0:23:51.090,0:23:54.970
Wszyscy go używali jeszcze kilka lat temu

0:23:54.970,0:24:00.370
TensorFlow utknął w martwym punkcie. W zasadzie TensorFlow utknął w martwym punkcie.

0:24:00.370,0:24:05.930
Pojawiło się inne oprogramowanie o nazwie PyTorch, które było o wiele łatwiejsze w użyciu i o wiele bardziej

0:24:05.930,0:24:15.040
przydatne dla naukowców i w ostatnich
12 miesiącach, odsetek artykułów naukowych na głównych

0:24:15.040,0:24:21.290
konferencjach, które korzystają z PyTorch, wzrósł z 20% do 80% i na odwrót, ci, którzy używają

0:24:21.290,0:24:24.960
TensorFlow zmalało z 80% do 20%.

0:24:24.960,0:24:29.030
Więc w zasadzie wszyscy ludzie, którzy są w zasadzie tworzą technologię, z której wszyscy korzystamy,

0:24:29.030,0:24:35.340
teraz używają PyTorch-a i wiesz, branża zmienia się nieco wolniej, ale w następnym roku lub

0:24:35.340,0:24:38.900
dwóch prawdopodobnie zobaczysz podobną rzecz w branży.

0:24:38.900,0:24:45.180
W PyTorch chodzi o to, że jest bardzo
bardzo elastyczny i naprawdę jest zaprojekowany do

0:24:45.180,0:24:52.570
elastyczności i łatwości programowania, napewno nie jest zaprojektowany dla początkujących

0:24:52.570,0:24:57.950
I nie jest przeznaczony do tego, co nazywamy, nie ma interfejsu API wyższego poziomu, tu mam na myśli

0:24:57.950,0:25:05.630
że nie ma środków tak naprawdę do zbudowania rzeczy szybko za pomocą PyTorch.

0:25:05.630,0:25:13.700
Aby poradzić sobie z tym problemem, mamy bibliotekę zwaną fastai, która znajduje się powyżej PyTorch-a.

0:25:13.700,0:25:20.330
Fastai jest najpopularniejszym API wyższego poziomu dla PyTorch-a.

0:25:20.330,0:25:27.520
Ponieważ nasze kursy są tak popularne,
niektórzy ludzie mają błędne wrażenie

0:25:27.520,0:25:34.260
że fastai jest zaprojektowane dla początkujących lub do nauczania.

0:25:34.260,0:25:43.840
Jest przeznaczona dla początkujących i nauczania, a także praktyków w przemyśle i badaczy.

0:25:43.840,0:25:50.290
Sposób, w jaki to robimy, zapewnia, że jest
to najlepszy interfejs API dla wszystkich tych osób

0:25:50.290,0:25:59.340
ponieważ używamy czegoś co się nazywa warstwowym API. I jest recenzowana praca, którą Sylvain

0:25:59.340,0:26:04.600
i ja napisaliśmy, w której opisaliśmy, jak to zrobiliśmy. I a dla tych z was, którzy są inżynierami oprogramowania,

0:26:04.600,0:26:08.130
nie będzie to wcale niezwykłe ani zaskakujące.

0:26:08.130,0:26:12.590
To po prostu całkowicie standardowe praktyki inżynierii oprogramowania, ale są to praktyki, które

0:26:12.590,0:26:17.030
nie występowały w żadnej bibliotece do głębokiego uczenia, które widzieliśmy.

0:26:17.030,0:26:24.500
Zasadniczo po prostu dużo refaktoryzacji i oddzielania, a więc stosując to podejście, pozwoliło nam

0:26:24.500,0:26:32.410
zbudować coś, co możesz użyć do super badań niskiego poziomu, możesz zrobić najnowocześniejsze

0:26:32.410,0:26:43.850
modele produkcyjne i możesz zrobić coś super łatwego, dla początkujących, ale modele światowej klasy początkujących.

0:26:43.850,0:26:47.220
To jest podstawowy zesetaw oprogramowania. Bedą też inne elementy oprogramowania, których będziemy się uczyć

0:26:47.220,0:26:49.940
po drodze.

0:26:49.940,0:26:54.570
Ale, myślę, że to najważniejsze, i chcę o tym wspomnieć, że to właściwie nie ma znaczenia.

0:26:54.570,0:27:01.300
Jeśli nauczysz się tego zestawu oprogramowania, a następnie
w pracy będziesz używać TensorFlow i Keras,

0:27:01.300,0:27:06.380
będziesz mógł się przestawić w krócej niż
tydzień.

0:27:06.380,0:27:13.070
Wielu studentów tak zrobiło,
to nigdy nie było problemem.

0:27:13.070,0:27:20.700
Ważne jest, aby nauczyć się podstaw
dlatego skupimy się na tych pojęciach

0:27:20.700,0:27:27.870
i za pomocą interfejsu API, który minimalizuje ilość 'boilerplate', które musisz użyć, to znaczy, że Ty

0:27:27.870,0:27:29.730
możesz skupić się na ważnych rzeczach.

0:27:29.730,0:27:38.150
Rzeczywiste wiersze kodu będą dużo bardziej odpowiadać do faktycznych koncepcji, które wdrażasz.

0:27:38.150,0:27:41.450
Będziecie potrzebowali maszyny z GPU.

0:27:41.450,0:27:49.420
GPU to jednostka przetwarzania grafiki, a konkretnie
potrzebujesz procesora graficznego Nvidia.

0:27:49.420,0:27:55.520
Inne marki GPU po prostu nie są dobrze obsługiwane
przez biblioteki do głębokiego uczenia.

0:27:55.520,0:27:56.970
Proszę ich nie kupować..

0:27:56.970,0:28:00.130
Jeśli już to macie, prawdopodobnie nie powinniście tego używać.

0:28:00.130,0:28:05.400
Zamiast tego powinniście użyć jednej z platform, które dla Was przygotowaliśmy.

0:28:05.400,0:28:10.410
To jest ogromne rozproszenie, spędzanie czasu na robienie rzeczy jak, administracja systemu

0:28:10.410,0:28:16.330
na komputerze z procesorem graficznym i instalowaniem sterowników oraz
bla bla bla.

0:28:16.330,0:28:18.000
I używaj go w systemie Linux.

0:28:18.000,0:28:19.000
Proszę.

0:28:19.000,0:28:22.260
Tak robią wszyscy, nie tylko my,
wszyscy używają go w systemie Linux.

0:28:22.260,0:28:23.370
Ułatw sobie życie.

0:28:23.370,0:28:28.200
Jest wystarczająco trudno nauczyć się głębokiego uczenia bez
robienie tego w sposób, w którym uczysz się

0:28:28.200,0:28:31.550
wiesz, wszystkiego rodzaju problemów związanych ze sprzętem.

0:28:31.550,0:28:43.480
Dostępnych jest wiele bezpłatnych opcji i
więc proszę, proszę skorzystaj z nich.

0:28:43.480,0:28:48.280
Jeśli korzystasz z opcji, która nie jest darmowa, nie zapomnij wyłączyć instancji.

0:28:48.280,0:28:51.730
Więc co się stanie. Będziesz
uruchamiać serwer, który znajduję się gdzieś

0:28:51.730,0:28:57.260
indziej  na świecie, a ty się połączysz do niego ze swego komputera i będziesz trenował

0:28:57.260,0:29:01.500
uruchamiał i budował modele.

0:29:01.500,0:29:05.980
Tylko dlatego, że zamkniesz okno przeglądarki, nie oznacza, że serwer przestaje pracować

0:29:06.980,0:29:07.980
Dobrze.

0:29:07.980,0:29:11.330
Więc nie zapomnij go wyłączyć, bo inaczej będziesz płacić za to.

0:29:11.330,0:29:16.120
Colab, to świetny system, który jest bezpłatny.

0:29:16.120,0:29:18.650
Istnieje również wersja płatnej subskrypcji
tego.

0:29:18.650,0:29:21.200
Ostrożnie z Colabem.

0:29:21.200,0:29:26.590
Większość innych systemów, które zalecamy, zapisuje Twoja prace automatycznie i możesz

0:29:26.590,0:29:28.460
wróć do tego w dowolnym momencie.

0:29:28.460,0:29:29.460
Colab nie.

0:29:29.460,0:29:37.110
Więc koniecznie sprawdź wątek o platformie Colab na forach, aby się o tym dowiedzieć.

0:29:37.110,0:29:44.020
Wspominam więc o forach ...

0:29:44.020,0:29:51.970
Fora są naprawdę bardzo bardzo ważne, ponieważ tam właśnie odbywa się cała dyskusja i konfiguracja

0:29:51.970,0:29:54.030
i wszystko inne się dzieje.

0:29:54.030,0:29:56.240
Na przykład, jeśli potrzebujesz pomocy z konfiguracją, tutaj

0:29:56.240,0:30:03.820
Wiesz, jest wątek pomocy konfiguracji i
możesz dowiedzieć się, jak najlepiej ustawić Colab

0:30:03.820,0:30:09.150
i możesz zobaczyć dyskusje na temat, i możesz zadawać pytania i proszę pamiętaj

0:30:09.150,0:30:12.310
szukać, zanim zadasz pytanie, prawda.






0:40:01.849,0:40:04.259
Więc pomysł jest taki.

0:40:04.259,0:40:10.480
To jest właściwie ta wersja, z którą chcesz eksperymentować.

0:40:10.480,0:40:15.170
Ponieważ zmusza cię ona do myślenia o tym, co się dzieje na każdym kroku

0:40:15.170,0:40:18.799
a nie tylko do czytania i uruchamiania go bez zastanowienia.

0:40:18.799,0:40:24.059
Chcemy, żebyś robił to w małym, nagim środowisku, w którym myślisz jak o tym

0:40:24.059,0:40:28.859
co mówiła książka, dlaczego tak się dzieje i jeśli o czymś zapomnisz

0:40:28.859,0:40:31.321
to wracasz do książki.

0:40:31.321,0:40:36.910
Inną rzeczą, o której należy wspomnieć jest zarówno kurs w wersji V4, jak i `fastbook` wersja książkowa

0:40:36.910,0:40:42.000
na końcu mają pytania.

0:40:42.000,0:40:46.529
I sporo osób powiedziało nam, że wiesz, że wśród recenzentów, że

0:40:46.529,0:40:49.990
oni tak naprawdę przeczytali te pytania na początku.

0:40:49.990,0:40:57.869
Spędziliśmy wiele, wiele tygodni pisząc te pytania, Sylvain i ja.

0:40:57.869,0:41:04.380
A powód tego jest taki, że staramy się myśleć o tym, co chcemy, abyś

0:41:04.380,0:41:07.680
zapamiętał z każdego notatnika.

0:41:07.680,0:41:10.029
Więc jeśli przeczytasz pytania na początku

0:41:10.029,0:41:12.150
Dowiesz się które rzeczy my uważamy za istotne.

0:41:12.150,0:41:14.940
Które rzeczy powinniście wiedzieć zanim przejdziesz dalej

0:41:14.940,0:41:20.040
Więc zamiast mieć podsumowanie na końcu, które mówi, że powinieneś wiedzieć, blah blah blah,

0:41:20.360,0:41:23.660
W zamian tego mamy pytania, które spełniają to samo zadanie.

0:41:23.960,0:41:27.720
Więc proszę pamiętaj żeby odpowiedzieć na pytania zanim przejdziesz do następnego roździału.

0:41:27.720,0:41:31.600
Nie musisz odpowiedzieć poprawnie na wszystkie pytania i w większości odpowiadanie na pytania

0:41:31.600,0:41:37.999
jest tak proste jak powrót do tej częsci notatnika i przeczytania tekstu

0:41:38.000,0:41:44.460
ale jeśli coś przeoczyłeś, wróć i przeczytaj to, bo to są rzeczy, któe zakładamy, że znasz.

0:41:44.960,0:41:50.420
Więc jeśli nie opanowaliści tych rzeczy zanim przejdziecie dalej, może to być frustrujące.

0:41:50.420,0:41:57.499
Jednakże, jeżeli utkniecie mimo tego żę próbowaliście kilka razy, przejdźcie do  następnego rozdziału,

0:41:57.499,0:42:00.809
Zrób dwa lub trzy rozdziały a potem wróć.

0:42:00.809,0:42:05.300
może do czasu, gdy zrobisz jeszcze kilka rozdziałów, wiesz, będziesz miał trochę więcej perspektywy.

0:42:05.480,0:42:10.540
Staramy się wyjaśniać rzeczy wielokrotnie na różne sposoby, so it's okay if you tried

0:42:10.840,0:42:14.140
więc nie ma problemu, jeśli spróbujesz i utkniesz

0:42:14.140,0:42:17.320
wtedy możesz iść dalej.

0:42:21.120,0:42:26.400
W porządku, więc spróbujmy uruchomić pierwszą część notatnika.

0:42:26.400,0:42:37.480
Więc tutaj jesteśmy w 01 intro, więc to jest to rozdział 1 i tutaj jest nasza pierwsza komórka.

0:42:37.480,0:42:46.280
Więc klikam na komórkę i domyślnie, faktycznie, będzie tam nagłówek na pasku narzędzi, jak widać.

0:42:46.480,0:42:47.480
Można go włączać i wyłączać

0:42:47.481,0:42:53.640
Ja zawsze go zostawiam. Więc aby uruchomić tą komórkę, można albo klinknąć na 'play'

0:42:53.640,0:42:56.940
przycisk uruchamiania lub jak wspomniałem, można nacisnąć 'shift' 'enter'

0:42:56.940,0:43:04.100
Więc dla tego jednego to po prostu klikam i jak widać ta gwiazda pojawia się, więc to mówi, że jest uruchomiona

0:43:04.500,0:43:08.780
a teraz możesz zobaczyć, jak wyskakuje pasek postępu, który zajmie kilka sekund

0:43:09.080,0:43:15.680
i jak się wykonuje będzie wyświetlał wyniki

0:43:15.680,0:43:18.740
Nie oczekuj, że uzyskasz dokładnie takie same wyniki jak my

0:43:19.020,0:43:23.779
jest pewna przypadkowość związana z trenowaniem modelu, i to jest w porządku.

0:43:23.780,0:43:26.530
Nie oczekuj, że uzyskasz dokładnie takie same czasy, jak my.

0:43:26.530,0:43:33.360
Jeśli ta pierwsza komórka zajmuje więcej niż pięć minut, chyba że masz naprawdę stary procesor graficzny, to jest prawdopodobnie złym znakiem.

0:43:33.500,0:43:38.600
Możesz wejść na forum i dowiedzieć się, co się dzieje.

0:43:38.609,0:43:43.400
a może używasz Windows, który w tej chwili naprawdę nie działają zbyt dobrze.

0:43:43.400,0:43:45.210
Nie martw się, że nie wiemy jeszcze, co robi cały ten kod.

0:43:45.210,0:43:49.680
Staramy się tylko o to, żebyśmy mogli wytrenować model.

0:43:50.300,0:43:52.300
Więc oto jesteśmy, skończyło się wykonywać.

0:43:52.400,0:43:56.420
i jak widzisz, zostało wydrukowane kilka informacji.

0:43:56.700,0:44:05.260
i w tym przypadku pokazuje mi to, że jest poziom błędu 0,005 przy robieniu czegoś.

0:44:05.269,0:44:06.569
Co to coś robi?

0:44:06.569,0:44:14.089
Cóż, to co tu robi, to tak naprawdę pobiera zestaw danych, nazywamy go zestawem danych o zwierzętach domowych (pets dataset)

0:44:14.089,0:44:18.849
który jest zestawem danych ze zdjęciami kotów i psów

0:44:18.849,0:44:25.829
I próbuje się dowiedzieć, które z nich są kotami, a które psami.

0:44:25.829,0:44:34.560
I jak widać, po mniej niż minucie jest w stanie to zrobić z błędem 0,5%

0:44:34.800,0:44:37.039
Więc może to zrobić całkiem idealnie.

0:44:37.039,0:44:39.509
Więc wytrenowaliśmy nasz pierwszy model

0:44:39.509,0:44:40.539
Nie mamy pojęcia jak

0:44:40.539,0:44:41.799
Nie wiemy, co robiliśmy

0:44:41.799,0:44:44.259
Ale rzeczywiście wytrenowaliśmy nasz model

0:44:44.259,0:44:46.559
Więc to dobry początek

0:44:46.559,0:44:51.309
I jak widzisz, możemy trenować modele dość szybko na jednym komputerze.

0:44:51.309,0:44:55.089
Który wiecie - Wiele z nich można używać za darmo

0:44:55.089,0:45:00.869
Jeszcze jedna rzecz, o której należy wspomnieć, jeśli masz Mac-a - nie ma znaczenia, czy masz Windows

0:45:00.869,0:45:05.069
Mac czy Linux, jeśli chodzi o to, co jest uruchamiane w przeglądarce

0:45:05.069,0:45:11.470
Ale jeśli masz Maca, proszę nie próbuj używać tego układu GPU

0:45:11.470,0:45:16.150
Tak naprawdę Mac - Apple nie obsługuje już nawet procesorów graficznych Nvidia

0:45:16.150,0:45:19.470
Więc to naprawdę nie będzie świetna opcja

0:45:19.470,0:45:20.869
Więc trzymaj się Linuksa.

0:45:20.869,0:45:25.010
Dzięki temu życie stanie się dla Ciebie dużo łatwiejsze

0:45:25.010,0:45:30.420
Racja, tak naprawdę pierwszą rzeczą, którą powinniśmy zrobić, jest wypróbowanie tego

0:45:30.420,0:45:34.750
Więc jeśli - twierdzę, że wytrenowaliśmy model, który potrafi odróżniać koty od psów

0:45:34.750,0:45:37.640
Upewnijmy się, że możemy

0:45:37.640,0:45:41.859
Więc sprawdźmy tę komórkę

0:45:41.860,0:45:42.860
To jest interesujące, prawda

0:45:43.100,0:45:47.940
Stworzyliśmy obiekt `widgets.FileUpload` i wyświetliliśmy go

0:45:47.940,0:45:50.690
A to faktycznie pokazuje nam przycisk, który możemy kliknąć

0:45:50.690,0:45:52.619
Więc jak wspomniałem, to jest niezwykły REPL

0:45:52.619,0:45:55.319
Możemy nawet stworzyć GUI, w tym REPL

0:45:55.319,0:45:58.359
Więc jeśli kliknę na ten `file upload`

0:45:58.359,0:46:00.170
I mogę wybrać 'kot'

0:46:00.170,0:46:04.130
Proszę bardzo

0:46:04.130,0:46:11.230
I mogę teraz zamienić te przesłane dane w obrazek

0:46:11.230,0:46:14.319
To jest kot

0:46:14.320,0:46:19.200
I teraz mogę użyć predykcji `predict`

0:46:19.200,0:46:21.200
i to jest kot

0:46:21.500,0:46:26.400
Z prawdopodobieństwem 99,96%

0:46:26.400,0:46:29.910
Więc widzimy, że właśnie wgraliśmy obraz, który wybraliśmy

0:46:29.910,0:46:30.930
Więc powinniście tego spróbować

0:46:30.930,0:46:31.930
Dobrze

0:46:31.930,0:46:32.930
Weź zdjęcie kota

0:46:32.930,0:46:35.579
Znajdź zdjęcie z Internetu albo sam zrób zdjęcie

0:46:35.579,0:46:38.910
I upewnij się, że dostaniesz zdjęcie kota

0:46:38.910,0:46:43.520
To jest coś, co może rozpoznać zdjęcia kotów, a nie rysunki kreskowe kotów

0:46:43.520,0:46:46.940
I tak jak zobaczymy, w tym kursie

0:46:46.940,0:46:52.050
Tego rodzaju modele mogą się uczyć tylko z tych informacji, które im przekazujesz

0:46:52.050,0:46:57.130
A jak na razie podaliśmy tylko, jak się dowiesz, zdjęcia kotów

0:46:57.130,0:47:06.700
Nie koty anime, nie koty rysunkowe, nie abstrakcyjne przedstawienia kotów, tylko zdjęcia

0:47:06.700,0:47:11.470
Więc teraz przyjrzymy się, co tu się właściwie wydarzyło

0:47:11.470,0:47:15.930
I zobaczysz w tej chwili, nie dostaję tu żadnych wielkich informacji

0:47:15.930,0:47:26.259
Jeśli widzisz to, w swoich notatnikach, będziesz musiał zrobić: `File -> Trust Notebook`

0:47:26.259,0:47:30.559
I to tylko mówi Jupyter-owi, że może uruchomić kod niezbędny do wyświetlania rzeczy

0:47:30.559,0:47:33.509
aby upewnić się, że nie ma żadnych problemów z bezpieczeństwem

0:47:33.509,0:47:35.880
I tak teraz zobaczysz wynik

0:47:35.880,0:47:39.880
Czasami widzisz jakiś dziwny kod, jak ten

0:47:39.880,0:47:43.609
To jest kod który w zasadzie tworzy wyniki

0:47:43.609,0:47:46.349
Więc czasami ukrywamy ten kod

0:47:46.349,0:47:47.800
Czasami go pokazujemy

0:47:47.800,0:47:52.560
Więc ogólnie rzecz biorąc, można po prostu zignorować takie rzeczy i skupić się na tym, co wychodzi

0:47:52.940,0:47:54.300
Więc nie zamierzam przez to przechodzić

0:47:54.300,0:48:00.660
Zamiast tego przyjrzę się temu - to samo tutaj, na slajdach

0:48:00.660,0:48:04.710
Więc to, co tu robimy to jest uczenie maszynowe

0:48:04.710,0:48:07.750
Głębokie uczenie jest rodzajem uczenia maszynowego

0:48:07.750,0:48:09.170
Czym jest uczenie maszynowe?

0:48:09.170,0:48:16.070
Uczenie się maszynowe jest, tak jak zwykłe programowanie, sposobem na sprawienie , by komputery coś zrobiły.

0:48:16.070,0:48:21.140
Ale w tym przypadku dość trudno jest zrozumieć, w jaki sposób można wykorzystać zwykłe programowanie

0:48:21.320,0:48:24.000
do rozpoznawania zdjęć psów od kotów

0:48:24.000,0:48:28.319
W jaki sposób tworzysz pętle i zmienne przypisania oraz warunki

0:48:28.319,0:48:31.789
do tworzenia programu, który rozpoznaje psy i koty na zdjęciach

0:48:31.789,0:48:33.190
To jest bardzo trudne

0:48:33.190,0:48:34.589
Bardzo bardzo trudne

0:48:34.589,0:48:41.420
Tak trudne, że do czasów ery głębokiego uczenia, nikt tak naprawdę nie miał modelu, który byłby wystarczająco dokładny w tym niby łatwym zadaniu

0:48:41.420,0:48:43.910
w tym niby łatwym zadaniu

0:48:43.910,0:48:46.970
Bo nie możemy zapisać niezbędnych kroków

0:48:46.970,0:48:51.369
Więc normalnie, wiesz, zapisujemy funkcję, która pobiera niektóre wejścia i przechodzi przez nasz

0:48:51.369,0:48:52.369
program

0:48:52.369,0:48:55.569
Generuje pewne wyniki

0:48:55.569,0:49:02.530
Tak więc ten ogólny pomysł, gdzie program jest czymś, gdzie zapisujemy kroki

0:49:02.530,0:49:06.970
Nie wydaje się, żeby to było dobre dla takich rzeczy jak rozpoznawanie obrazów

0:49:06.970,0:49:12.470
Tak więc już w 1949 roku, ktoś o nazwisku Arthur Samuel zaczął próbować znaleźć sposób na rozwiązanie

0:49:12.470,0:49:16.030
problemów, takich jak rozpoznawanie zdjęć kotów i psów

0:49:16.030,0:49:23.000
A w 1962 roku opisał sposób, w jaki można to zrobić

0:49:23.000,0:49:26.270
Otóż najpierw opisał problem: "Zaprogramowanie komputera do tego typu

0:49:26.270,0:49:31.070
obliczeń jest w najlepszym wypadku trudnym zadaniem

0:49:31.070,0:49:37.589
Ze względu na konieczność opisania każdego pojedynczego kroku procesu w irytujących szczegółach

0:49:37.589,0:49:42.290
Komputery są gigantycznymi kretynami, co wszyscy z nas, programistów, całkowicie rozpoznają."

0:49:42.290,0:49:46.769
Powiedział więc, okay, nie mówmy komputerowi o dokładnych krokach, ale podajmy mu przykłady

0:49:46.769,0:49:50.460
problemu do rozwiązania i dowiedzmy się, jak on sam go rozwiąże

0:49:50.460,0:49:56.269
I tak, w 1961 roku zbudował program do gry w warcaby, który pokonał mistrza stanu Connecticut

0:49:56.269,0:50:03.450
nie mówiąc mu, jakie kroki należy podjąć, aby grać w warcaby, ale zamiast tego, to, czym jest:

0:50:03.450,0:50:09.990
"zorganizować automatyczny sposób badania skuteczności przypisania wag

0:50:09.990,0:50:15.690
pod względem rzeczywistej wydajności oraz mechanizm zmiany przypisania wag w celu

0:50:15.690,0:50:19.019
zmaksymalizowania wydajności"

0:50:19.019,0:50:21.680
To zdanie jest kluczowe

0:50:21.680,0:50:24.440
I jest to dość podchwytliwe zdanie, więc możesz spędzić nad nim trochę czasu

0:50:24.440,0:50:32.200
Podstawową ideą jest to, że zamiast mówić wejścia do programu, a następnie wyjścia

0:50:32.200,0:50:36.430
Mamy dane wejściowe do - nazwijmy program teraz modelem

0:50:36.430,0:50:38.140
To jest ta sama podstawowa idea

0:50:38.140,0:50:40.349
Wejścia do modelu i wyniki

0:50:40.349,0:50:43.760
I wtedy będziemy mieli drugą rzecz zwaną wagami

0:50:43.760,0:50:50.569
I tak podstawowa idea jest taka, że model ten jest czymś, co wytwarza wyniki nie tylko na podstawie

0:50:50.569,0:50:58.410
na przykład, stanu szachownicy, ale także w oparciu o jakiś zestaw wag lub parametrów

0:50:58.410,0:51:02.320
które opisują, jak ten model będzie działać

0:51:02.320,0:51:09.039
Chodzi więc o to, że gdybyśmy mogli wymienić wszystkie możliwe sposoby gry w warcaby

0:51:09.040,0:51:15.640
a następnie opisać każdy z tych sposobów za pomocą jakiegoś zestawu parametrów lub tego, co Samuel nazywał wagami.

0:51:15.820,0:51:22.600
Następnie, gdybyśmy mieli sposób na sprawdzenie, jak skuteczne jest bieżące przypisanie wagi w odniesieniu do rzeczywistych wyników

0:51:22.800,0:51:29.760
innymi słowy, czy to konkretne określenie strategii gry w warcaby kończy się wygraniem lub przegraniem gry

0:51:29.760,0:51:35.400
a następnie sposób na zmianę przypisania wagi tak, aby zmaksymalizować wyniki

0:51:35.600,0:51:40.710
Więc spróbujmy zwiększyć lub zmniejszyć każdą z tych wag pojedynczo

0:51:40.710,0:51:44.220
aby dowiedzieć się, czy istnieje nieco lepszy sposób gry w warcaby

0:51:44.480,0:51:50.880
a następnie zrobić to wiele razy, po czym na końcu taka procedura mogłaby być całkowicie zautomatyzowana

0:51:51.220,0:51:55.400
i wtedy tak zaprogramowana maszyna nauczyłaby się ze swojego doświadczenia

0:51:55.520,0:52:00.200
więc ten mały akapit jest, jest sednem problemu

0:52:00.200,0:52:01.620
To jest uczenie maszynowe

0:52:01.880,0:52:11.340
sposób tworzenia programów tak, aby się uczyły, a nie były programowane

0:52:11.340,0:52:16.860
więc gdybyśmy mieli coś takiego, to w zasadzie mielibyśmy teraz coś, co wygląda jak to

0:52:17.000,0:52:23.240
masz dane wejściowe i wagi jeszcze raz, wychodzące do modelu, tworząc wyniki, tzn. wygrałeś lub przegrałeś

0:52:23.500,0:52:26.760
a następnie pomiar skuteczności.

0:52:26.760,0:52:30.840
Więc pamiętaj, że to był ten kluczowy krok, a potem drugi kluczowy krok to sposób na aktualizację wag

0:52:31.080,0:52:35.600
w oparciu o zmierzone wyniki, a następnie można przejść w pętli przez ten proces

0:52:35.609,0:52:43.450
i stworzyć, wytrenować model uczenia maszynowego, więc to jest abstrakcyjny pogląd

0:52:43.450,0:52:49.260
Więc po pewnym czasie, prawda, pojawił się zestaw wag, które są dość dobre

0:52:49.260,0:52:55.089
Dobrze, możemy teraz zapomnieć o sposobie, w jaki był trenowany i mamy coś

0:52:55.089,0:53:02.359
co jest właśnie takie, prawda, z wyjątkiem słowa program, które jest teraz zastąpione przez słowo model

0:53:02.359,0:53:07.239
Tak więc wytrenowany model może być używany jak każdy inny program komputerowy

0:53:07.239,0:53:13.509
Tak więc pomysł jest taki, że budujemy program komputerowy nie poprzez definiowanie niezbędnych kroków

0:53:13.509,0:53:20.600
do wykonania zadania, ale poprzez trenowanie go tak, aby nauczył się wykonywać zadanie, na końcu którego jest tylko kolejnym programem

0:53:20.840,0:53:31.200
a więc to, co nazywa się wnioskowaniem (inference) dobrze jest to używanie wytrenowanego modelu jako programu do wykonywania zadań takich jak granie w warcaby

0:53:33.320,0:53:42.980
Tak więc uczenie maszynowe jest trenowaniem programów stworzonych poprzez umożliwienie komputerowi uczenia się na podstawie jego doświadczeń, a nie poprzez ręczne kodowanie

0:53:46.000,0:53:53.640
Dobrze, jak to zrobić dla rozpoznawania obrazów, jaki jest ten model i jaki zestaw wag

0:53:53.640,0:53:59.700
taki, że jak je zmieniamy, może stawać się coraz lepszy w rozpoznawaniu kotów i psów

0:53:59.700,0:54:02.210
To znaczy w warcabach

0:54:02.210,0:54:05.240
Nietrudno sobie wyobrazić, jak można by to wyliczyć

0:54:05.500,0:54:12.100
w zależności od tego, jak bardzo pionek przeciwnika jest oddalony od twojego pionka, co powinieneś zrobić w tej sytuacji

0:54:12.280,0:54:16.079
Jak powinieneś rozważyć strategie obronne kontra agresywne, bla bla bla.

0:54:16.079,0:54:20.410
Wcale nie jest to oczywiste, jak się to robi dla rozpoznawania obrazu.

0:54:20.410,0:54:29.240
Tak więc to, czego naprawdę chcemy, to jakaś funkcja, która jest tak elastyczna,

0:54:29.240,0:54:33.210
że istnieje zestaw wag, które mogą spowodować, że zrobi wszystko.

0:54:33.210,0:54:37.960
Prawdziwa - jak najbardziej elastyczna z możliwych funkcji na świecie

0:54:38.280,0:54:41.059
i okazuje się, że coś takiego istnieje

0:54:41.059,0:54:44.140
To jest sieć neuronowa

0:54:44.140,0:54:50.329
Więc opiszemy dokładnie czym jest ta matematyczna funkcja na kolejnych lekcjach

0:54:50.329,0:54:56.160
Aby jej użyć, tak naprawdę nie ma znaczenia co to jest tą funkcją matematyczną

0:54:56.160,0:55:02.320
Jest to funkcja, o której mówimy, że jest "sparametryzowana" przez jakiś zestaw wag

0:55:02.540,0:55:08.880
przez co rozumiem, że kiedy daję jej inny zestaw wag, wykonuje ona inne zadanie

0:55:09.300,0:55:16.540
i faktycznie może wykonać każde możliwe zadanie: coś, co nazywamy twierdzeniem o uniwersalnej zbieżności

0:55:16.540,0:55:26.320
mówi nam, że matematycznie sprawdzalna forma funkcjonalna może rozwiązać każdy problem, który można rozwiązać na dowolnym poziomie dokładności

0:55:26.320,0:55:28.589
Jeśli tylko znajdziesz odpowiedni zestaw wag

0:55:28.589,0:55:35.580
Co jest rodzajem powtórzenia tego, co opisaliśmy wcześniej w tym, jak mamy do czynienia z problemem Minsky-ego (Marvin Minsky)

0:55:35.580,0:55:40.700
Więc sieci neuronowe są tak elastyczne, że jeżeli znajdziesz odpowiedni zestaw wag

0:55:40.980,0:55:45.860
mogą rozwiązać każdy problem, w tym "Czy to kot, czy to pies"

0:55:46.280,0:55:50.020
Oznacza to, że musisz skoncentrować swój wysiłek na procesie ich trenowania

0:55:50.340,0:55:57.000
czyli na znalezieniu dobrych wag, dobrych przypisań wag, aby używać terminologii Samuela

0:55:57.010,0:55:59.770
Więc jak to robisz?

0:55:59.770,0:56:09.239
Chcemy, aby to zrobić w całkowicie ogólny sposób - zaktualizować wagi w oparciu o pewną miarę wydajności

0:56:09.239,0:56:14.200
np. jak dobre jest rozpoznawanie kotów w porównaniu z psami

0:56:14.200,0:56:16.839
I na szczęście okazuje się, że coś takiego istnieje!

0:56:16.839,0:56:21.539
A ta rzecz nazywa się stochastycznym gradientem prostym (lub SGD).

0:56:21.540,0:56:26.240
Jeszcze raz przyjrzymy się dokładnie jak to działa, sami zbudujemy to od podstaw

0:56:26.380,0:56:28.520
ale na razie nie musimy się tym martwić.

0:56:28.520,0:56:34.980
Powiem wam jednak, że ani SGD, ani sieci neuronowe nie są wcale skomplikowane matematycznie.

0:56:35.200,0:56:38.820
Prawie w całości są one dodawaniem i mnożeniem.

0:56:38.820,0:56:46.000
Sztuczka polega na tym, że jest ich tylko ogromna ilość - jak miliardy - tak wiele więcej, niż jesteśmy w stanie intuicyjnie pojąć.

0:56:46.100,0:56:52.940
Potrafią robić niezwykle potężne rzeczy, ale nie są wcale czymś skomplikowanym.

0:56:52.940,0:56:58.609
Nie są rzeczami skomplikowanymi i zobaczymy dokładnie, jak działają.

0:56:58.609,0:57:03.049
Więc to jest wersja Arthura Samuela, prawda.

0:57:03.049,0:57:08.580
Obecnie nie używamy tej samej terminologii, ale używamy dokładnie tej samej idei.

0:57:08.580,0:57:14.300
Więc tę funkcję, która znajduje się w środku, nazywamy architekturą.

0:57:14.540,0:57:20.779
Architektura to funkcja, z którą dostosowujemy wagi, żeby coś wykonać

0:57:20.779,0:57:24.190
To jest architektura, to jest funkcjonalna forma modelu

0:57:24.190,0:57:28.849
Czasami ludzie mówią, że model oznacza architekturę, więc nie pozwól, aby to zbytnio cię zmyliło

0:57:28.849,0:57:30.559
Ale naprawdę właściwym słowem jest architektura

0:57:30.559,0:57:34.619
Nie nazywamy ich wagami, nazywamy je parametrami

0:57:34.619,0:57:40.410
Wagi mają konkretne znaczenie - to dość szczególny rodzaj parametru

0:57:40.410,0:57:49.420
Rzeczy, które wychodzą z modelu, architektura z parametrami, nazywamy ich przewidywaniami

0:57:49.800,0:57:53.020
Przewidywania opierają się na dwóch rodzajach danych wejściowych

0:57:53.320,0:57:57.960
niezależnych zmiennych, czyli danych, takich jak zdjęcia kotów i psów

0:57:58.220,0:58:03.300
oraz zmiennych zależnych, zwanych też etykietami

0:58:03.300,0:58:08.060
czyli takich, które mówią "to jest kot", "to jest pies", "to jest kot"

0:58:08.400,0:58:09.779
Więc, to są twoje dane wejściowe

0:58:09.779,0:58:12.769
Więc, wyniki są przewidywaniami

0:58:12.769,0:58:18.670
Miarą wydajności, używając słowa Arthura Samuela, jest strata

0:58:18.670,0:58:23.280
Tak więc, strata jest obliczana na podstawie etykiet na przewidywaniach

0:58:23.440,0:58:26.720
 a następnie jest aktualizowana z powrotem do parametrów

0:58:26.720,0:58:33.980
Okay, więc, to jest ten sam obraz, który widzieliśmy, ale używając słów, z których korzystamy dzisiaj

0:58:34.200,0:58:40.020
Tak więc, ten obrazek - jeśli zapomnisz, jeśli powiem, że są to parametry wykorzystane w tej architekturze

0:58:40.039,0:58:44.220
do stworzenia modelu - możesz wrócić i przypomnieć sobie, co one oznaczają

0:58:44.220,0:58:45.220
Czym są te parametry?

0:58:45.220,0:58:46.500
Czym są przewidywania?

0:58:46.500,0:58:47.500
Czym jest strata?

0:58:47.500,0:58:52.580
Okay, strata jakiejś funkcji, która mierzy wydajność modelu

0:58:52.900,0:58:56.780
w taki sposób, że możemy aktualizować parametry

0:58:56.790,0:59:06.170
Tak więc, należy zauważyć, że głębokie uczenie i uczenie maszynowe nie są magią, prawda?

0:59:06.170,0:59:14.580
Model może być stworzony tylko wtedy, gdy posiadasz dane pokazujące przykłady rzeczy, o których próbujesz się nauczyć. 

0:59:14.860,0:59:21.820
Może on nauczyć się tylko operować na wzorcach, które widziałeś w danych wejściowych używanych do jego trenowania, prawda?

0:59:22.020,0:59:27.100
Tak więc, jeśli nie mamy żadnych rysunków kreskowych kotów i psów, to nigdy nie będzie

0:59:27.100,0:59:34.200
aktualizacji parametrów, które sprawiają, że architektura, a więc architektura i parametry razem są modelem

0:59:34.420,0:59:40.100
Tak więc, mówiąc o modelu, która sprawia, że model lepiej przewiduje rysunki kotów i psów

0:59:40.100,0:59:46.420
ponieważ po prostu, nigdy nie otrzymał tych aktualizacji wag, ponieważ nigdy nie otrzymał tych danych wejściowych

0:59:46.680,0:59:51.239
Zauważ również, że to podejście do uczenia zawsze tworzy tylko przewidywania

0:59:51.239,0:59:54.319
Nie mówi ci ono, co masz z tym zrobić

0:59:54.319,0:59:58.019
To będzie bardzo ważne, gdy będziemy myśleć o takich rzeczach jak system rekomendacji

0:59:58.019,1:00:01.230
w stylu "jaki produkt komuś polecamy"?

1:00:01.230,1:00:04.950
Cóż, nie wiem... Nie robimy tego, prawda?

1:00:04.575,1:00:07.515
Możemy przewidywać co ktoś

1:00:07.515,1:00:10.095
powie o produkcie po jego zobaczeniu

1:00:10.095,1:00:10.595
Ale nie generujemy akcji,

1:00:10.595,1:00:12.095
tworzymy predykcje

1:00:12.095,1:00:13.115
To bardzo ważne

1:00:13.615,1:00:15.945
 rozróżnienie

1:00:17.245,1:00:20.235
Nie wystarczy mieć tylko przykładów wejściowych 

1:00:20.235,1:00:23.405
jak zdjęcia psów i kotów

1:00:23.405,1:00:25.335
potrzebujemy też etykiet

1:00:28.535,1:00:30.185
Bardzo często kiedy ktoś mówi że nie ma wystarczającej ilości danych

1:00:30.695,1:00:33.755
tak na prawdę ma na myśli że nie ma poetykietowanych danych

1:00:33.755,1:00:36.545
Ponieważ kiedy firma próbuje 

1:00:36.545,1:00:39.155
używać Deep Learning

1:00:39.155,1:00:45.065
Często robi to by zautomatyzować lub polepszyć

1:00:45.065,1:00:48.485
coś co już robią, więc z definicji, mają już dane o tym czymś, lub sposób ich pozyskania

1:00:48.675,1:00:51.455
bo już ich używają

1:00:51.455,1:00:54.325
Ale często trudnością jest etykietowanie

1:00:54.325,1:00:56.705
Na przykład w medycynie

1:00:57.275,1:01:00.175
Jeśli chcecie stworzyć model dla prześwietleń

1:01:00.425,1:01:03.335
Na pewno da się zebrać dużo zdjęć rentgenowskich

1:01:03.335,1:01:06.195
Prawie każdego typu

1:01:06.685,1:01:09.875
Ale może być trudno przypisać im etykiety 

1:01:09.875,1:01:12.955
Opisujące złośliwość nowotworu

1:01:12.955,1:01:15.775
albo o wystąpieniu czerniaka

1:01:15.815,1:01:18.565
ponieważ tego typu etykiety nie są przechowywane

1:01:18.565,1:01:21.585
w łatwo dostępny sposób

1:01:21.585,1:01:22.835
przynajmniej nie w amerykańskiej służbie zdrowia

1:01:24.275,1:01:27.215
Więc to jest istotne rozróżnienie które wpływa

1:01:27.215,1:01:28.335
na waszą strategię

1:01:31.755,1:01:34.735
Więc model wg tego co widzieliśmy w książce PDP

1:01:34.740,1:01:37.740
Operuje wewnątrz środowiska

1:01:42.120,1:01:45.440
Implementujecie go i coś nim robicie

1:01:45.900,1:01:47.880
Ta część modelu PDP

1:01:47.885,1:01:50.515
jest bardzo ważna

1:01:50.515,1:01:53.525
Macie model który potrafi coś zrobić

1:01:53.525,1:01:56.565
Na przykład model działań policji

1:01:56.565,1:01:59.235
który przewiduje

1:01:59.235,1:02:02.475
gdzie może zostać dokonane aresztowanie

1:02:02.545,1:02:05.755
coś co jest często używane w USA

1:02:06.275,1:02:09.275
Predykcje są wykonywane na podstawie danych i etykiet

1:02:09.275,1:02:12.005
W tym przykładzie 

1:02:12.005,1:02:14.485
będzie używał danych

1:02:14.485,1:02:17.505
na przykładzie USA

1:02:20.095,1:02:22.915
W zależności czy jesteście czarno czy białoskórzy

1:02:22.915,1:02:25.955
czarnoskórzy są aresztowani około 

1:02:25.955,1:02:28.955
7 razy częściej za posiadanie marihuany

1:02:28.955,1:02:32.215
niż biali

1:02:32.535,1:02:35.435
Pomimo że skala użytkowania marihuany 

1:02:35.435,1:02:38.415
jest mniej więcej taka sama dla obu populacji

1:02:38.415,1:02:41.115
Więc jeśli opieracie się na skrzywionych danych

1:02:41.115,1:02:44.345
by zbudować model dla policji. Przewidywania modelu będą

1:02:44.545,1:02:48.035
sugerowały miejsca aresztowań w oparciu o 

1:02:48.345,1:02:51.585
te skrzywione dane. Więc więcej policjantów

1:02:51.585,1:02:54.475
Skupi swoje działania

1:02:54.475,1:02:57.735
Na obszarach wskazywanych przez predykcje

1:02:58.325,1:03:01.325
W wyniku czego znajdą tam ludzi do zaaresztowania

1:03:01.565,1:03:04.945
i wpuszczą tą informację z powrotem do modelu

1:03:05.035,1:03:07.145
który teraz będzie przewidywał

1:03:07.145,1:03:10.115
jeszcze więcej aresztów w czarnych dzielnicach

1:03:10.115,1:03:13.015
i w ten sposób się zapętlamy

1:03:13.015,1:03:15.735
To jest przykład modelu który przez interakcje ze środowiskiem

1:03:15.735,1:03:18.895
tworzy sprzężenie zwrotne

1:03:19.375,1:03:22.305
Im więcej model jest używany tym bardziej 

1:03:22.305,1:03:25.595
dane są skrzywione, co czyni model jeszcze bardziej skrzywionym itd

1:03:26.175,1:03:28.725
Więc rzeczą na którą trzeba bardzo uważać

1:03:28.725,1:03:32.035
w nauczaniu maszynowym jest zrozumienie

1:03:32.035,1:03:33.005
jak

1:03:33.005,1:03:36.075
model jest używany

1:03:36.075,1:03:38.325
i jakie mogą być tego konsekwencje

1:03:41.945,1:03:44.885
Chciałabym dodać że jest to również przykład

1:03:44.885,1:03:47.455
zamiennika, ponieważ

1:03:47.455,1:03:50.525
aresztowania są użyte jako przybliżenie dla przestępczości

1:03:50.525,1:03:53.255
Myślę że zwykle

1:03:53.255,1:03:56.325
dane które macie

1:03:56.325,1:03:59.395
są tylko przybliżeniem tego na czym tak na prawdę wam zależy

1:03:59.395,1:04:02.515
Różnica między tym przybliżeniem a prawdziwą wartością

1:04:02.515,1:04:04.775
często okazuje się istotna

1:04:09.845,1:04:12.195
Dzięki Rachel, to bardzo trafna uwaga

1:04:13.735,1:04:16.555
Dobrze więc

1:04:16.555,1:04:19.715
na koniec  zobaczmy

1:04:20.415,1:04:23.255
co się dzieje w tym kodzie

1:04:23.855,1:04:25.865
Kod który uruchamialiśmy

1:04:28.475,1:04:31.585
to w zasadzie 1, 2, 3, 4, 5, 6

1:04:31.585,1:04:33.915
Sześć linijek kodu

1:04:35.845,1:04:37.305
Pierwsza linijka

1:04:38.195,1:04:40.855
To import

1:04:41.475,1:04:44.475
w Pythonie żeby użyć zewnętrznej biblioteki

1:04:44.475,1:04:46.185
trzeba z niej zaimportować

1:04:46.555,1:04:49.365
zwykle w Pythonie programiści

1:04:49.365,1:04:52.325
importują tylko funkcje i klasy które potrzebują

1:04:52.325,1:04:55.275
z tej biblioteki

1:04:55.275,1:04:58.005
Python udostępnia też wygodny sposób

1:04:58.005,1:05:01.055
na zaimportowanie wszystkiego z modułu 

1:05:01.055,1:05:03.865
poprzez symbol *

1:05:03.865,1:05:06.895
Zwykle nie jest to dobry pomysł

1:05:06.895,1:05:09.895
ponieważ domyślnie 

1:05:09.895,1:05:12.805
kiedy importujecie * Python nie importuje tylko

1:05:12.805,1:05:14.215
tych rzeczy 

1:05:14.215,1:05:17.165
Które są istotne w bibliotece 

1:05:17.165,1:05:20.185
której chcecie użyć

1:05:20.185,1:05:22.935
ale także ze wszystkich bibliotek które ona używa itd

1:05:22.935,1:05:25.775
W rezultacie wasza przestrzeń nazw eksploduje

1:05:25.775,1:05:28.765
w okropny sposób i powoduje najróżniejsze błędy

1:05:29.245,1:05:32.195
Ponieważ fastai jest zaprojektowane do użytku

1:05:32.195,1:05:34.935
 wewnątrz środowiska REPL 

1:05:34.935,1:05:37.955
gdzie chcecie móc

1:05:37.955,1:05:40.915
szybko prototypować. Poświęciliśmy wiele czasu 

1:05:40.915,1:05:43.775
na rozwiązanie tego problemu

1:05:43.775,1:05:46.635
żeby import * było bezpieczne

1:05:46.635,1:05:49.425
Czy chcecie tego używać czy nie

1:05:49.425,1:05:52.305
zależy od was, ale wiedzcie że import * 

1:05:52.305,1:05:54.895
z biblioteki fastai

1:05:54.895,1:05:57.705
jest zaprojektowane tak że 

1:05:57.705,1:06:00.885
dostajecie tylko części których potrzebujecie

1:06:01.595,1:06:04.485
Zwróćcie uwagę że w filmie widzicie fastai2

1:06:04.485,1:06:07.465
ponieważ w czasie nagrywania

1:06:07.465,1:06:10.495
używamy wersji pre-release

1:06:10.495,1:06:13.465
Kiedy będziecie to otwierać

1:06:13.465,1:06:16.475
jako kurs online, dwójki już nie będzie

1:06:18.480,1:06:20.600
Kolejną rzeczą wartą wspomnienia jest

1:06:21.020,1:06:24.165
że są, na ten moment, cztery główne 

1:06:24.165,1:06:26.545
predefiniowane zagadnienia wewnątrz fastai

1:06:26.545,1:06:28.695
 obraz, tekst

1:06:29.015,1:06:32.215
dane tabularne i collaborative filtering

1:06:32.215,1:06:35.145
o których będziemy uczyć się później

1:06:35.145,1:06:38.065
Dla każdego z nich, na przykład vision

1:06:38.065,1:06:40.905
możecie importować z meta modułu .all 

1:06:40.905,1:06:43.925
i to zamiportuje rzeczy które

1:06:43.925,1:06:46.905
najczęściej używa się 

1:06:46.905,1:06:49.905
w przetwarzaniu obrazów

1:06:49.905,1:06:53.035
Kiedy używacie systemu REPL jak jupyter notebook

1:06:53.035,1:06:56.005
Udostępni wam to wszystko co potrzebujecie 

1:06:56.005,1:06:59.295
bez potrzeby zastanawiania się nad tym

1:07:04.435,1:07:06.865
Kłopot z takim rozwiązaniem jest że wielu użytkowników Pythona

1:07:08.665,1:07:11.565
kiedy widzi coś jak untar_data 

1:07:11.565,1:07:14.545
patrzy na importy by zrozumieć skąd się to bierze

1:07:14.545,1:07:17.525
z import * tego nie widać

1:07:17.525,1:07:19.465
Na szczęście REPL

1:07:19.465,1:07:21.235
udostępnia inne sposoby

1:07:22.695,1:07:26.145
wystarczy wpisać symbol i wcisną Shift+Enter by zobaczyć

1:07:26.545,1:07:28.005
dokładne źródło

1:07:28.405,1:07:31.065
Jak widzicie. Niesamowicie przydatne

1:07:33.155,1:07:35.005
Na przykład tutaj

1:07:35.445,1:07:38.515
przy tworzeniu zbioru danych

1:07:38.515,1:07:42.015
wywołujemy ImageDataLoaders.from_name_func

1:07:42.345,1:07:45.315
mogę w tym przypadku wywołać

1:07:45.315,1:07:47.855
specjalną funkcję doc 

1:07:47.855,1:07:49.375
by zobaczyć dokumentację 

1:07:50.005,1:07:52.975
Jak widzicie

1:07:52.975,1:07:56.195
pokazuje mi dokładne parametry z wartościami domyślnymi

1:07:56.195,1:07:59.015
a co najważniejsze

1:07:59.015,1:08:02.215
oprócz opisu co robi jest link "Show in docs"

1:08:02.405,1:08:04.815
który prowadzi do

1:08:05.185,1:08:08.155
pełnej dokumentacji

1:08:08.155,1:08:09.165
łącznie z przykładem

1:08:09.975,1:08:12.645
cała dokumentacja fastai

1:08:12.645,1:08:15.745
ma przykłady

1:08:15.745,1:08:18.705
a najfajniejsze jest to że ta dokumentacja 

1:08:18.705,1:08:21.445
jest napisane w jupyter notebook

1:08:21.445,1:08:23.775
dzięki temu możecie otworzyć notebook 

1:08:23.775,1:08:26.775
dla tego dokumentu i uruchomić linię kodu

1:08:26.775,1:08:30.255
żeby zobaczyć że działa, zobaczyć wartość wyjściową itd

1:08:32.385,1:08:35.215
W dokumentacji znajdziecie również

1:08:35.215,1:08:37.525
różne tutoriale

1:08:37.525,1:08:40.480
na przykład jeśli popatrzycie na "Vision tutorial" obejmuje on różne tematy

1:08:40.480,1:08:43.560
 jeden z nich, jest jak widzicie ,

1:08:43.565,1:08:46.560
obejmuje te same zagadnienia którymi zajmujemy się w lekcji 1

1:08:46.775,1:08:49.665
Jest mnóstwo dokumentacji w fastai

1:08:49.665,1:08:52.725
i warto z niej korzystać

1:08:52.725,1:08:55.655
W całości wspiera wyszukiwanie

1:08:55.655,1:08:58.705
i jak już wspominałem

1:08:58.705,1:09:01.765
każda z tych stron dokumentacji jest też

1:09:01.765,1:09:03.285
interaktywną stroną jupyter notebook

1:09:04.895,1:09:07.825
Patrząc na pozostały kod

1:09:10.820,1:09:13.840
 Pierwsza linijka po imporcie

1:09:13.840,1:09:16.815
wywołuje untar_data

1:09:16.815,1:09:20.265
to ściągnie zbiór danych, rozpakuje i zapisze na waszym dysku

1:09:20.355,1:09:22.765
jeśli już był ściągnięty nie będzie ściągać ponownie

1:09:22.765,1:09:25.625
jeśli jest już rozpakowany nie będzie próbować rozpakowywać

1:09:25.625,1:09:28.355
jak widzicie tutaj fastai ma 

1:09:28.355,1:09:31.325
dostęp do predefiniowanych użytecznych danych

1:09:31.325,1:09:34.085
jak ten zbiór PETS

1:09:35.515,1:09:38.675
Możecie się domyślić że zbiory danych są bardzo istotną częścią

1:09:38.675,1:09:41.715
Deep learningu będziemy używać

1:09:41.715,1:09:44.735
różnych  z nich. Które zostały stworzone przez wielu bohaterów

1:09:44.755,1:09:47.815
którzy spędzili miesiące a nawet lata

1:09:47.815,1:09:51.035
zbierając dane które możemy teraz używać w swoich modelach

1:09:53.605,1:09:57.075
Następny krok to poinstruowanie fastai

1:09:57.255,1:10:00.205
czym są te dane i spędzimy wiele czasu na 

1:10:00.205,1:10:02.795
nauce o tym. W tym przykładzie

1:10:02.795,1:10:04.485
piszemy że dane to pliki graficzne

1:10:05.105,1:10:08.345
z tej lokalizacji

1:10:08.345,1:10:10.235
untar_data zwraca ścieżkę

1:10:10.805,1:10:13.595
do katalogu gdzie pliki zostały  teraz rozpakowane

1:10:13.595,1:10:16.075
lub jeśli były wcześniej rozpakowane

1:10:16.075,1:10:18.725
zwraca tamtą ścieżkę

1:10:18.725,1:10:21.475
Musimy też podać

1:10:21.475,1:10:23.035
jakie pliki są w tej lokalizacji

1:10:23.635,1:10:26.935
Ciekawym szczegółem jest funkcja etykietująca

1:10:26.935,1:10:30.135
Jak rozpoznać dla każdego pliku

1:10:30.355,1:10:32.665
czy ma to być kot czy pies

1:10:33.245,1:10:36.035
Jeśli zerkniecie do pliku README dla tego zbioru danych

1:10:36.035,1:10:38.905
Używa trochę nietypowego sposobu

1:10:38.905,1:10:41.585
Pliki których nazwa zaczyna się od wielkiej litery

1:10:41.585,1:10:44.645
to kot

1:10:44.785,1:10:47.675
tak to zaprojektowali. Więc stworzyliśmy tu krótką funkcję

1:10:47.675,1:10:50.525
is_cat która sprawdza

1:10:50.525,1:10:53.405
czy nazwa zaczyna się w wielkiej litery i przekazujemy fastai

1:10:53.405,1:10:55.745
że w ten sposób może rozpoznać pliki z kotami

1:10:58.335,1:11:01.075
do tych dwóch wrócimy za chwilę

1:11:01.075,1:11:04.025
teraz kiedy przekazaliśmy jak wyglądają dane

1:11:04.025,1:11:06.965
musimy stworzyć coś co nazywamy learner

1:11:06.965,1:11:10.015
learner jest odpowiedzialny za naukę, trening

1:11:10.015,1:11:13.005
musicie mu przekazać jakich danych użyć

1:11:13.005,1:11:15.565
i jakiej architektury użyć

1:11:17.755,1:11:20.715
będziemy jeszcze wiele o tym mówić, ale w skrócie

1:11:20.715,1:11:23.105
istnieje dużo predefiniowanych architektur sieci neuronowych

1:11:23.105,1:11:26.095
które mają swoje wady i zalety

1:11:26.095,1:11:29.085
dla zagadnień graficznych

1:11:29.085,1:11:31.880
architektura resnet jest świetnym wyborem na początek

1:11:31.880,1:11:35.080
będziemy tu używać dosyć niewielkiej wersji tej architektury

1:11:35.360,1:11:38.260
te różne architektury są już dla was

1:11:38.275,1:11:40.715
zdefiniowane i skonfigurowane w bibliotece

1:11:40.715,1:11:43.785
Następnie musicie poinstruować fastai co powinno wypisywać w czasie nauczania

1:11:43.785,1:11:46.995
w tym przypadku: proszę wyświetlać wielkość  błędu

1:11:47.295,1:11:50.295
Później wywołujemy tą bardzo istotną metodę fine_tune

1:11:50.295,1:11:53.215
o której będziemy się uczyć w następnej lekcji

1:11:53.215,1:11:54.925
jest ona odpowiedzialna za nauczanie

1:11:56.335,1:11:59.135
valid_pct jest ważną rzeczą

1:11:59.925,1:12:02.825
wybiera ono, w tym przypadku,

1:12:02.825,1:12:05.565
20 procent danych

1:12:05.995,1:12:08.985
i nie używa ich podczas nauczania

1:12:08.985,1:12:12.365
zamiast tego używa ich do wyliczenia wartości błędu

1:12:12.365,1:12:14.985
Tak więc zawsze w fastai

1:12:14.985,1:12:18.005
ta metryka error_rate

1:12:18.005,1:12:20.915
jest wyliczona na podstawie części zbioru danych

1:12:20.915,1:12:24.035
który nie był używany do nauczania

1:12:24.035,1:12:26.825
Ta idea, o której będziemy jeszcze dyskutować w przyszłości,

1:12:26.825,1:12:29.395
polega na tym że

1:12:29.395,1:12:32.675
chcemy się upewnić że spowodujemy nadmiernego dopasowania

1:12:32.745,1:12:35.735
Nadmierne dopasowanie wygląda tak: chcecie znaleźć funkcję 

1:12:35.735,1:12:38.605
która przechodzi przez te punkty

1:12:38.605,1:12:41.505
Dobra funkcja wyglądałaby tak

1:12:42.015,1:12:43.015
racja?

1:12:43.105,1:12:45.585
Ale możecie również

1:12:45.585,1:12:48.505
dopasować funkcję o wiele dokładniej

1:12:48.505,1:12:51.615
Zobaczcie ta przechodzi bliżej punktów niż tamta

1:12:51.615,1:12:54.655
Więc wygląda to na lepszą funkcję. Tyle że

1:12:54.655,1:12:57.565
jeśli popatrzycie poza punktami

1:12:57.565,1:12:58.735
zwłaszcza na krawędziach

1:12:59.255,1:13:01.925
okazuje się że nie ma ona sensu

1:13:01.925,1:13:04.715
To właśnie nazywamy nadmiernym dopasowaniem

1:13:04.865,1:13:05.865
funkcji

1:13:06.135,1:13:09.085
Nadmierne dopasowanie ma różne przyczyny

1:13:09.085,1:13:12.125
Użycie zbyt dużego modelu, lub za mało danych

1:13:12.125,1:13:15.425
Będziemy się tym wszystkim jeszcze zajmować

1:13:16.805,1:13:19.745
Ale tak na prawdę cała sztuka w Deep Learningu

1:13:19.745,1:13:22.835
to tworzenie modelu który jest odpowiednio dopasowany

1:13:22.835,1:13:25.845
a jedyny sposób żeby wiedzieć że jest odpowiednio dopasowany

1:13:25.845,1:13:28.805
to sprawdzenie czy działa dobrze dla danych

1:13:28.805,1:13:31.635
które nie były użyte w trakcie nauki

1:13:31.635,1:13:34.745
dlatego zawsze wyłączamy część danych

1:13:34.745,1:13:37.825
by stworzyć z nich coś co nazywamy zbiorem walidacyjnym

1:13:37.825,1:13:40.415
Są to dane których 

1:13:40.415,1:13:42.035
nie tykamy w trakcie nauczania

1:13:42.385,1:13:44.905
A jedynie do sprawdzenia

1:13:44.905,1:13:47.615
czy nasz model na prawdę działa, czy nie.

1:13:50.200,1:13:53.680
Jedna z rzeczy o której Sylvain pisze w książce

1:13:54.100,1:13:57.005
to że interesującą częścią 

1:13:57.005,1:14:00.020
uczenia się z fastai jest to

1:14:00.025,1:14:01.715
że uczycie się wiele o 

1:14:02.065,1:14:05.045
samym programowaniu

1:14:05.045,1:14:07.685
ja programuję od dziecka 

1:14:07.685,1:14:10.695
więc już 40 lat

1:14:10.695,1:14:14.035
Sylvain i ja bardzo się staramy by

1:14:14.035,1:14:17.095
Używać Pythona w sposób

1:14:17.095,1:14:20.095
pasuje do naszych potrzeb

1:14:20.095,1:14:23.115
By używać praktyk które

1:14:23.115,1:14:26.075
pozwalają nam wrócić do kodu po latach i ciągle go rozumieć

1:14:26.165,1:14:28.265
Jak się przekonacie

1:14:30.335,1:14:33.145
Nasz kod piszemy w sposób 

1:14:33.145,1:14:36.195
którego mogliście wcześniej nie spotkać

1:14:36.195,1:14:38.595
wielu uczniów poprzednich kursów

1:14:38.595,1:14:41.505
powiedziało nam że nauczyli się wiele o kodowaniu, 

1:14:41.505,1:14:44.475
używaniu Pythona i inżynierii oprogramowania z tego kursu

1:14:44.475,1:14:47.625
więc jeśli zobaczycie coś nowego

1:14:47.625,1:14:50.535
przyjrzyjcie się temu i nie wahajcie spytać na forum czemu 

1:14:50.535,1:14:51.565
zostało to zrobione w dany sposób

1:14:52.065,1:14:55.135
Kolejną rzeczą

1:14:55.135,1:14:57.285
podobnie jak wspominałem o import *

1:14:57.285,1:15:00.165
którego większość programistów Pythona nie używa

1:15:00.165,1:15:01.745
bo większość bibliotek

1:15:02.355,1:15:05.635
nie wspiera robienia tego bezpiecznie

1:15:05.685,1:15:08.155
Również w wielu innych miejscach 

1:15:08.155,1:15:11.165
nie trzymamy się tradycyjnego podejścia do programowania w Pythonie

1:15:12.935,1:15:15.925
Używałem tylu różnych języków programowania przez lata

1:15:16.255,1:15:18.975
że programuję w sposób

1:15:18.975,1:15:21.635
który jest Pythoniczny

1:15:21.635,1:15:25.095
Inkorporuję idee z innych języków i notacji

1:15:26.725,1:15:29.685
i mocno spersonalizowałem nasze podejście

1:15:29.685,1:15:32.655
do Pythona żeby pasowało dobrze dla Data Science

1:15:33.655,1:15:36.485
to znaczy że kod który zobaczycie w fastai

1:15:36.485,1:15:39.505
najprawdopodobniej nie będzie pasował do

1:15:39.505,1:15:42.505
rekomendowanego stylu

1:15:42.505,1:15:45.275
w waszej pracy, jeśli używacie Pythona

1:15:45.455,1:15:47.535
Więc oczywiście musicie

1:15:47.535,1:15:50.505
dopasować się do rekomendacji 

1:15:50.505,1:15:53.845
waszych organizacji 

1:15:54.395,1:15:57.435
zamiast naszych

1:15:57.435,1:16:00.075
Ale może w swoich prywatnych projektach możecie 

1:16:00.285,1:16:03.075
wypróbować nasz sposób i sprawdzić czy jest przydatny

1:16:03.345,1:16:06.475
Albo poeksperymentować w swojej firmie jeśli jesteście managerami i chcecie tego spróbować

1:16:10.915,1:16:14.385
Okay, na koniec pokażę wam coś ciekawego

1:16:15.755,1:16:18.025
spójrzcie na

1:16:19.085,1:16:20.085
ten kod

1:16:20.235,1:16:21.745
untar_data

1:16:22.335,1:16:25.015
ImageDataLoaders.from_name_func

1:16:25.015,1:16:26.085
learner, fine_tune

1:16:27.025,1:16:29.635
untar_data, SegmentationDataLoaders.from_label_func

1:16:29.635,1:16:32.865
learner, fine_tune

1:16:33.115,1:16:34.675
prawie identyczny kod

1:16:35.275,1:16:38.525
i to stworzyło model który robi... wow! Coś całkiem innego

1:16:38.525,1:16:41.585
Coś co przyjmuje obrazy

1:16:41.585,1:16:44.575
Po lewej są

1:16:44.575,1:16:47.695
Poetykietowane dane, obrazki gdzie kolory odpowiadają obiektom

1:16:47.695,1:16:50.525
czy jest to samochód, czy drzewo

1:16:50.525,1:16:53.305
czy budynek, niebo, pasy, droga

1:16:53.765,1:16:56.695
a po prawej wynik działania naszego modelu

1:16:56.695,1:16:59.575
Model poradził sobie z przypisaniem każdemu pikselowi

1:16:59.685,1:17:02.645
czy należy do samochodu, pasowi, drodze

1:17:02.645,1:17:04.415
zajęło to tylko

1:17:05.245,1:17:08.165
poniżej 30 sekund, jest to mały szybki model

1:17:08.165,1:17:11.665
popełnił trochę błędów jak część tego pasa na drodze 

1:17:11.745,1:17:14.555
czy niektórych samochodów czy domów

1:17:14.555,1:17:17.675
ale jak widzicie jeśli 

1:17:17.675,1:17:20.695
pouczylibyście go przez kilka minut będzie działał prawie idealnie

1:17:22.395,1:17:24.825
Podstawowa idea to że 

1:17:24.825,1:17:27.945
możemy bardzo szybko, używając prawie tego samego kodu

1:17:27.945,1:17:31.095
zrobić coś co nie odróżnia kotów od psów

1:17:31.095,1:17:34.135
a robi coś co nazywamy segmentacją. Rozumie czym jest każdy piksel w obrazie

1:17:35.475,1:17:38.445
Zobaczcie, znów to samo.
from ... import *

1:17:38.445,1:17:40.445
TextDataLoaders.from_folder
learner

1:17:40.445,1:17:41.415
learn.fine_tune

1:17:41.415,1:17:43.545
ta sama struktura kodu

1:17:44.575,1:17:47.705
To nam dało coś co w oparciu o zdanie

1:17:47.715,1:17:50.775
potrafi określi czy opisuje ono pozytywną 

1:17:50.775,1:17:53.275
czy negatywną opinię

1:17:53.275,1:17:55.985
Robi to z dokładnością 93%

1:17:57.255,1:17:59.605
po 15 minutach nauczania

1:18:00.335,1:18:03.445
na zbiorze danych IMDB

1:18:03.445,1:18:06.365
który zawiera tysiące pełnych recenzji filmów 

1:18:06.365,1:18:09.695
zawierających 1000 do 3000 słów

1:18:09.785,1:18:12.595
Wynik który tu osiągnęliśmy , tymi samymi trzema linijkami kodu

1:18:12.595,1:18:14.285
byłby najlepszy na świecie

1:18:14.795,1:18:17.775
dla tego problemu na tym bardzo popularnym zbiorze danych

1:18:17.775,1:18:18.775
w roku 2015

1:18:18.845,1:18:22.275
Więc tworzymy modele światowej klasy

1:18:22.515,1:18:25.725
w naszej przeglądarce

1:18:25.725,1:18:28.145
używając tego samego podstawowego kodu

1:18:31.655,1:18:34.615
Tutaj znowu te same kroki

1:18:34.615,1:18:37.735
from ... import *
untar_data
TabularDataLoaders.from_csv

1:18:37.735,1:18:39.465
learner
fit

1:18:39.815,1:18:42.705
Tym razem zbudowaliśmy model

1:18:42.705,1:18:46.055
który przewiduje... popatrzmy

1:18:46.055,1:18:47.055
pensje

1:18:47.495,1:18:50.485
na podstawie arkusza CSV zawierającego

1:18:51.375,1:18:54.035
te kolumny. Dane tabelaryczne

1:18:56.025,1:18:58.025
Znów te same podstawowe kroki
from ... import * 

1:18:58.025,1:18:59.065
untar_data

1:18:59.065,1:19:01.705
CollabDataLoaders.from_csv
learner

1:19:01.705,1:19:03.075
learn.fine_tune

1:19:03.755,1:19:05.815
To buduje model

1:19:06.235,1:19:09.125
który przewiduje dla filmu

1:19:09.125,1:19:11.525
i widza

1:19:11.995,1:19:15.105
 jak on go oceni na podstawie

1:19:15.105,1:19:18.255
innych filmów które oglądał i oceniał w przeszłości

1:19:18.255,1:19:21.155
nazywamy to Collaborative filtering

1:19:21.155,1:19:22.425
używane w systemach rekomendacji

1:19:22.885,1:19:25.925
Więc zobaczyliście przykłady każdego z czterech

1:19:25.925,1:19:28.495
zastosowań w fastai

1:19:29.045,1:19:31.965
i jak zobaczycie studiując ten kurs

1:19:31.965,1:19:34.705
ten sam podstawowy kod

1:19:34.705,1:19:37.435
i te same zasady matematyczne i architektoniczne

1:19:37.435,1:19:40.505
pozwalają nam robić

1:19:40.505,1:19:43.635
kompletnie różne rzeczy używając tego samego zasadniczego podejścia

1:19:43.635,1:19:46.855
Jest to możliwe dzięki Arthurowi Samuelowi  

1:19:46.965,1:19:50.385
Jego ogólnym opisie

1:19:50.745,1:19:53.685
co da się osiągnąć

1:19:53.685,1:19:56.785
jeśli jesteś w stanie sparametryzować model

1:19:56.785,1:19:59.805
i stworzyć procedurę update która

1:19:59.805,1:20:03.095
zmienia wagi w sposób który poprawia

1:20:03.485,1:20:06.435
wartość funkcji kosztu 

1:20:06.435,1:20:09.365
w tym przypadku możemy użyć sieci neuronowych

1:20:09.365,1:20:12.645
które spełniają rolę elastycznych funkcji

1:20:14.365,1:20:15.865
tak więc

1:20:16.905,1:20:19.835
To na tyle w pierwszej lekcji
była trochę krótsza

1:20:19.905,1:20:23.235
niż przyszłe lekcje. Spowodowane

1:20:23.235,1:20:26.305
jesteśmy teraz, jak wspominałem

1:20:26.305,1:20:29.135
na początku globalnej pandemii, przynajmniej tu na zachodzie

1:20:29.135,1:20:32.105
inne kraje są już w dalszej fazie

1:20:32.345,1:20:35.425
Poświęciliśmy trochę czasu na rozmowę o tym na początku

1:20:35.425,1:20:37.675
możecie to znaleźć w innym filmie

1:20:38.285,1:20:41.065
w kolejnych lekcjach

1:20:41.065,1:20:43.925
będzie więcej czasu na Deep Learning

1:20:45.475,1:20:47.985
teraz proponowałbym wam

1:20:47.985,1:20:51.215
przez następny tydzień

1:20:51.215,1:20:54.145
zanim przejdziecie do następnej lekcji

1:20:54.145,1:20:56.525
upewnijcie się że macie działający serwer z GPU

1:20:56.525,1:20:59.615
potraficie go wyłączyć kiedy skończycie

1:20:59.615,1:21:02.395
możecie uruchomić cały kod 

1:21:02.395,1:21:04.805
i czytając go 

1:21:04.805,1:21:07.555
zastanówcie się czy używa on Pythona w sposób który rozumiecie

1:21:07.975,1:21:11.355
Używajcie dokumentacji, funkcji doc()

1:21:13.195,1:21:16.145
Przeszukujcie dokumentacje zobaczcie jak działa

1:21:16.145,1:21:19.005
sprawdźcie czy możecie 

1:21:19.005,1:21:21.855
otworzyć notebooki z dokumentacją i je uruchomić

1:21:21.855,1:21:24.805
Spróbujcie zaznajomić się

1:21:24.805,1:21:27.705
z użytkowaniem tego wszystkiego, 
najważniejsze w tym

1:21:27.705,1:21:30.395
stylu nauki (z góry na dół)

1:21:30.395,1:21:33.575
to być w stanie przeprowadzać eksperymenty

1:21:33.575,1:21:36.155
a to znaczy uruchamiać kod

1:21:36.155,1:21:38.845
Więc sugeruję żebyście nie szli dalej zanim nie będziecie w stanie uruchamiać kodu

1:21:39.785,1:21:42.015
Przeczytajcie rozdział z książki

1:21:43.015,1:21:44.025
a następnie

1:21:44.535,1:21:47.345
Zróbcie ankietę

1:21:47.345,1:21:49.085
Część zagadnień mamy ciągle przed sobą

1:21:49.085,1:21:51.835
Więcej nauki o zbiorach walidacyjnych i testowych

1:21:51.835,1:21:54.725
o Transfer Learning, więc nie będziecie jeszcze w stanie odpowiedzieć na wszystkie pytania

1:21:54.975,1:21:58.015
ale postarajcie się odpowiedzieć na te na które możecie

1:21:58.015,1:22:00.835
na podstawie tego czego nauczyliście się dotychczas

1:22:01.965,1:22:04.965
Rachel czy masz coś do dodania?

1:22:04.965,1:22:07.505
W takim razie dziękuję wam bardzo za uwagę. Lekcja pierwsza zakończona

1:22:07.505,1:22:10.305
Do zobaczenia następnym razem

1:22:10.665,1:22:13.545
kiedy będziemy się uczyć o Transfer Learning

1:22:13.735,1:22:16.795
a następnie przejdziemy do stworzenia

1:22:16.795,1:22:19.815
działającej aplikacji

1:22:19.815,1:22:22.175
którą będziemy mogli

1:22:22.175,1:22:24.945
umieścić w internecie

1:22:24.945,1:22:28.445
i będziecie mogli zacząć tworzyć własne aplikacje i pokazywać swoim znajomym

1:22:29.005,1:22:30.785
Do zobaczenia!
